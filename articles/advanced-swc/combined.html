<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="Docutils 0.4: http://docutils.sourceforge.net/" />
<title>Intermediate and Advanced Software Carpentry in Python</title>
<meta name="author" content="C Titus Brown" />
<meta name="date" content="June 18, 2007" />
<style type="text/css">

/*
:Author: David Goodger
:Contact: goodger@users.sourceforge.net
:Date: $Date: 2005-12-18 01:56:14 +0100 (Sun, 18 Dec 2005) $
:Revision: $Revision: 4224 $
:Copyright: This stylesheet has been placed in the public domain.

Default cascading style sheet for the HTML output of Docutils.

See http://docutils.sf.net/docs/howto/html-stylesheets.html for how to
customize this style sheet.
*/

/* used to remove borders from tables and images */
.borderless, table.borderless td, table.borderless th {
  border: 0 }

table.borderless td, table.borderless th {
  /* Override padding for "table.docutils td" with "! important".
     The right padding separates the table cells. */
  padding: 0 0.5em 0 0 ! important }

.first {
  /* Override more specific margin styles with "! important". */
  margin-top: 0 ! important }

.last, .with-subtitle {
  margin-bottom: 0 ! important }

.hidden {
  display: none }

a.toc-backref {
  text-decoration: none ;
  color: black }

blockquote.epigraph {
  margin: 2em 5em ; }

dl.docutils dd {
  margin-bottom: 0.5em }

/* Uncomment (and remove this text!) to get bold-faced definition list terms
dl.docutils dt {
  font-weight: bold }
*/

div.abstract {
  margin: 2em 5em }

div.abstract p.topic-title {
  font-weight: bold ;
  text-align: center }

div.admonition, div.attention, div.caution, div.danger, div.error,
div.hint, div.important, div.note, div.tip, div.warning {
  margin: 2em ;
  border: medium outset ;
  padding: 1em }

div.admonition p.admonition-title, div.hint p.admonition-title,
div.important p.admonition-title, div.note p.admonition-title,
div.tip p.admonition-title {
  font-weight: bold ;
  font-family: sans-serif }

div.attention p.admonition-title, div.caution p.admonition-title,
div.danger p.admonition-title, div.error p.admonition-title,
div.warning p.admonition-title {
  color: red ;
  font-weight: bold ;
  font-family: sans-serif }

/* Uncomment (and remove this text!) to get reduced vertical space in
   compound paragraphs.
div.compound .compound-first, div.compound .compound-middle {
  margin-bottom: 0.5em }

div.compound .compound-last, div.compound .compound-middle {
  margin-top: 0.5em }
*/

div.dedication {
  margin: 2em 5em ;
  text-align: center ;
  font-style: italic }

div.dedication p.topic-title {
  font-weight: bold ;
  font-style: normal }

div.figure {
  margin-left: 2em ;
  margin-right: 2em }

div.footer, div.header {
  clear: both;
  font-size: smaller }

div.line-block {
  display: block ;
  margin-top: 1em ;
  margin-bottom: 1em }

div.line-block div.line-block {
  margin-top: 0 ;
  margin-bottom: 0 ;
  margin-left: 1.5em }

div.sidebar {
  margin-left: 1em ;
  border: medium outset ;
  padding: 1em ;
  background-color: #ffffee ;
  width: 40% ;
  float: right ;
  clear: right }

div.sidebar p.rubric {
  font-family: sans-serif ;
  font-size: medium }

div.system-messages {
  margin: 5em }

div.system-messages h1 {
  color: red }

div.system-message {
  border: medium outset ;
  padding: 1em }

div.system-message p.system-message-title {
  color: red ;
  font-weight: bold }

div.topic {
  margin: 2em }

h1.section-subtitle, h2.section-subtitle, h3.section-subtitle,
h4.section-subtitle, h5.section-subtitle, h6.section-subtitle {
  margin-top: 0.4em }

h1.title {
  text-align: center }

h2.subtitle {
  text-align: center }

hr.docutils {
  width: 75% }

img.align-left {
  clear: left }

img.align-right {
  clear: right }

ol.simple, ul.simple {
  margin-bottom: 1em }

ol.arabic {
  list-style: decimal }

ol.loweralpha {
  list-style: lower-alpha }

ol.upperalpha {
  list-style: upper-alpha }

ol.lowerroman {
  list-style: lower-roman }

ol.upperroman {
  list-style: upper-roman }

p.attribution {
  text-align: right ;
  margin-left: 50% }

p.caption {
  font-style: italic }

p.credits {
  font-style: italic ;
  font-size: smaller }

p.label {
  white-space: nowrap }

p.rubric {
  font-weight: bold ;
  font-size: larger ;
  color: maroon ;
  text-align: center }

p.sidebar-title {
  font-family: sans-serif ;
  font-weight: bold ;
  font-size: larger }

p.sidebar-subtitle {
  font-family: sans-serif ;
  font-weight: bold }

p.topic-title {
  font-weight: bold }

pre.address {
  margin-bottom: 0 ;
  margin-top: 0 ;
  font-family: serif ;
  font-size: 100% }

pre.literal-block, pre.doctest-block {
  margin-left: 2em ;
  margin-right: 2em ;
  background-color: #eeeeee }

span.classifier {
  font-family: sans-serif ;
  font-style: oblique }

span.classifier-delimiter {
  font-family: sans-serif ;
  font-weight: bold }

span.interpreted {
  font-family: sans-serif }

span.option {
  white-space: nowrap }

span.pre {
  white-space: pre }

span.problematic {
  color: red }

span.section-subtitle {
  /* font-size relative to parent (h1..h6 element) */
  font-size: 80% }

table.citation {
  border-left: solid 1px gray;
  margin-left: 1px }

table.docinfo {
  margin: 2em 4em }

table.docutils {
  margin-top: 0.5em ;
  margin-bottom: 0.5em }

table.footnote {
  border-left: solid 1px black;
  margin-left: 1px }

table.docutils td, table.docutils th,
table.docinfo td, table.docinfo th {
  padding-left: 0.5em ;
  padding-right: 0.5em ;
  vertical-align: top }

table.docutils th.field-name, table.docinfo th.docinfo-name {
  font-weight: bold ;
  text-align: left ;
  white-space: nowrap ;
  padding-left: 0 }

h1 tt.docutils, h2 tt.docutils, h3 tt.docutils,
h4 tt.docutils, h5 tt.docutils, h6 tt.docutils {
  font-size: 100% }

tt.docutils {
  background-color: #eeeeee }

ul.auto-toc {
  list-style-type: none }

</style>
</head>
<body>
<div class="document" id="intermediate-and-advanced-software-carpentry-in-python">
<h1 class="title">Intermediate and Advanced Software Carpentry in Python</h1>
<table class="docinfo" frame="void" rules="none">
<col class="docinfo-name" />
<col class="docinfo-content" />
<tbody valign="top">
<tr><th class="docinfo-name">Author:</th>
<td>C Titus Brown</td></tr>
<tr><th class="docinfo-name">Date:</th>
<td>June 18, 2007</td></tr>
</tbody>
</table>
<!-- @CTB
binary eggs?
multiproc code coverage -->
<p>Welcome!  You have stumbled upon the class handouts for a course I
taught at Lawrence Livermore National Lab, June 12-June 14, 2007.</p>
<p>These notes are intended to <em>accompany</em> my lecture, which was a
demonstration of a variety of &quot;intermediate&quot; Python features and
packages.  Because the demonstration was interactive, these notes are
not complete notes of what went on in the course.  (Sorry about that;
they <em>have</em> been updated from my actual handouts to be more
complete...)</p>
<p>However, all 70 pages are free to view and print, so enjoy.</p>
<p>All errors are, of course, my own.  Note that almost all of the
examples starting with '&gt;&gt;&gt;' are doctests, so you can take <a class="reference" href="combined.txt">the source</a> and run doctest on it to make sure I'm being honest.
But do me a favor and run the doctests with Python 2.5 ;).</p>
<p>Note that Day 1 of the course ran through the end of &quot;Testing Your
Software&quot;; Day 2 ran through the end of &quot;Online Resources for Python&quot;;
and Day 3 finished it off.</p>
<p>Example code (mostly from the C extension sections) is available <a class="reference" href="code.tar.gz">here</a>; see the <a class="reference" href="code/README.txt">README</a> for more information.</p>
<div class="contents topic">
<p class="topic-title first"><a id="contents" name="contents">Contents</a></p>
<ul class="simple">
<li><a class="reference" href="#idiomatic-python" id="id2" name="id2">Idiomatic Python</a><ul>
<li><a class="reference" href="#some-basic-data-types" id="id3" name="id3">Some basic data types</a></li>
<li><a class="reference" href="#list-comprehensions" id="id4" name="id4">List comprehensions</a></li>
<li><a class="reference" href="#building-your-own-types" id="id5" name="id5">Building your own types</a></li>
<li><a class="reference" href="#iterators" id="id6" name="id6">Iterators</a></li>
<li><a class="reference" href="#generators" id="id7" name="id7">Generators</a></li>
<li><a class="reference" href="#assert" id="id8" name="id8">assert</a></li>
<li><a class="reference" href="#conclusions" id="id9" name="id9">Conclusions</a></li>
</ul>
</li>
<li><a class="reference" href="#structuring-testing-and-maintaining-python-programs" id="id10" name="id10">Structuring, Testing, and Maintaining Python Programs</a><ul>
<li><a class="reference" href="#programming-for-reusability" id="id11" name="id11">Programming for reusability</a></li>
<li><a class="reference" href="#modules-and-scripts" id="id12" name="id12">Modules and scripts</a></li>
<li><a class="reference" href="#packages" id="id13" name="id13">Packages</a></li>
<li><a class="reference" href="#a-short-digression-naming-and-formatting" id="id14" name="id14">A short digression: naming and formatting</a></li>
<li><a class="reference" href="#another-short-digression-docstrings" id="id15" name="id15">Another short digression: docstrings</a></li>
<li><a class="reference" href="#sharing-data-between-code" id="id16" name="id16">Sharing data between code</a></li>
<li><a class="reference" href="#scoping-a-digression" id="id17" name="id17">Scoping: a digression</a></li>
<li><a class="reference" href="#back-to-sharing-data" id="id18" name="id18">Back to sharing data</a></li>
<li><a class="reference" href="#how-modules-are-loaded-and-when-code-is-executed" id="id19" name="id19">How modules are loaded (and when code is executed)</a></li>
<li><a class="reference" href="#pythonpath-and-finding-packages-modules-during-development" id="id20" name="id20">PYTHONPATH, and finding packages &amp; modules during development</a></li>
<li><a class="reference" href="#setup-py-and-distutils-the-old-fashioned-way-of-installing-python-packages" id="id21" name="id21">setup.py and distutils: the old fashioned way of installing Python packages</a></li>
<li><a class="reference" href="#setup-py-eggs-and-easy-install-the-new-fangled-way-of-installing-python-packages" id="id22" name="id22">setup.py, eggs, and easy_install: the new fangled way of installing Python packages</a></li>
</ul>
</li>
<li><a class="reference" href="#testing-your-software" id="id23" name="id23">Testing Your Software</a><ul>
<li><a class="reference" href="#an-introduction-to-testing-concepts" id="id24" name="id24">An introduction to testing concepts</a></li>
<li><a class="reference" href="#the-doctest-module" id="id25" name="id25">The doctest module</a></li>
<li><a class="reference" href="#unit-tests-with-unittest" id="id26" name="id26">Unit tests with unittest</a></li>
<li><a class="reference" href="#testing-with-nose" id="id27" name="id27">Testing with nose</a></li>
<li><a class="reference" href="#code-coverage-analysis" id="id28" name="id28">Code coverage analysis</a></li>
<li><a class="reference" href="#adding-tests-to-an-existing-project" id="id29" name="id29">Adding tests to an existing project</a></li>
<li><a class="reference" href="#concluding-thoughts-on-automated-testing" id="id30" name="id30">Concluding thoughts on automated testing</a></li>
</ul>
</li>
<li><a class="reference" href="#an-extended-introduction-to-the-nose-unit-testing-framework" id="id31" name="id31">An Extended Introduction to the nose Unit Testing Framework</a><ul>
<li><a class="reference" href="#what-are-unit-tests" id="id32" name="id32">What are unit tests?</a></li>
<li><a class="reference" href="#why-use-a-framework-and-why-nose" id="id33" name="id33">Why use a framework? (and why nose?)</a></li>
<li><a class="reference" href="#a-few-simple-examples" id="id34" name="id34">A few simple examples</a><ul>
<li><a class="reference" href="#test-fixtures" id="id35" name="id35">Test fixtures</a></li>
<li><a class="reference" href="#examples-are-included" id="id36" name="id36">Examples are included!</a></li>
</ul>
</li>
<li><a class="reference" href="#a-somewhat-more-complete-guide-to-test-discovery-and-execution" id="id37" name="id37">A somewhat more complete guide to test discovery and execution</a><ul>
<li><a class="reference" href="#running-tests" id="id38" name="id38">Running tests</a></li>
<li><a class="reference" href="#debugging-test-discovery" id="id39" name="id39">Debugging test discovery</a></li>
</ul>
</li>
<li><a class="reference" href="#the-nose-command-line" id="id40" name="id40">The nose command line</a><ul>
<li><a class="reference" href="#w-specifying-the-working-directory" id="id41" name="id41">-w: Specifying the working directory</a></li>
<li><a class="reference" href="#s-not-capturing-stdout" id="id42" name="id42">-s: Not capturing stdout</a></li>
<li><a class="reference" href="#v-info-and-debugging-output" id="id43" name="id43">-v: Info and debugging output</a></li>
<li><a class="reference" href="#specifying-a-list-of-tests-to-run" id="id44" name="id44">Specifying a list of tests to run</a></li>
</ul>
</li>
<li><a class="reference" href="#running-doctests-in-nose" id="id45" name="id45">Running doctests in nose</a></li>
<li><a class="reference" href="#the-attrib-plug-in-selectively-running-subsets-of-tests" id="id46" name="id46">The 'attrib' plug-in -- selectively running subsets of tests</a></li>
<li><a class="reference" href="#running-nose-programmatically" id="id47" name="id47">Running nose programmatically</a></li>
<li><a class="reference" href="#writing-plug-ins-a-simple-guide" id="id48" name="id48">Writing plug-ins -- a simple guide</a></li>
<li><a class="reference" href="#nose-caveats-let-the-buyer-beware-occasionally" id="id49" name="id49">nose caveats -- let the buyer beware, occasionally</a></li>
<li><a class="reference" href="#credits" id="id50" name="id50">Credits</a></li>
</ul>
</li>
<li><a class="reference" href="#idiomatic-python-revisited" id="id51" name="id51">Idiomatic Python revisited</a><ul>
<li><a class="reference" href="#sets" id="id52" name="id52">sets</a></li>
<li><a class="reference" href="#any-and-all" id="id53" name="id53"><tt class="docutils literal"><span class="pre">any</span></tt> and <tt class="docutils literal"><span class="pre">all</span></tt></a></li>
<li><a class="reference" href="#exceptions-and-exception-hierarchies" id="id54" name="id54">Exceptions and exception hierarchies</a></li>
<li><a class="reference" href="#function-decorators" id="id55" name="id55">Function Decorators</a></li>
<li><a class="reference" href="#try-finally" id="id56" name="id56">try/finally</a></li>
<li><a class="reference" href="#function-arguments-and-wrapping-functions" id="id57" name="id57">Function arguments, and wrapping functions</a></li>
</ul>
</li>
<li><a class="reference" href="#measuring-and-increasing-performance" id="id58" name="id58">Measuring and Increasing Performance</a><ul>
<li><a class="reference" href="#which-profiler-should-you-use" id="id59" name="id59">Which profiler should you use?</a></li>
<li><a class="reference" href="#measuring-code-snippets-with-timeit" id="id60" name="id60">Measuring code snippets with timeit</a></li>
</ul>
</li>
<li><a class="reference" href="#speeding-up-python" id="id61" name="id61">Speeding Up Python</a><ul>
<li><a class="reference" href="#psyco" id="id62" name="id62">psyco</a><ul>
<li><a class="reference" href="#installing-psyco" id="id63" name="id63">Installing psyco</a></li>
<li><a class="reference" href="#using-psyco" id="id64" name="id64">Using psyco</a></li>
</ul>
</li>
<li><a class="reference" href="#pyrex" id="id65" name="id65">pyrex</a></li>
</ul>
</li>
<li><a class="reference" href="#tools-to-help-you-work" id="id66" name="id66">Tools to Help You Work</a><ul>
<li><a class="reference" href="#ipython" id="id67" name="id67">IPython</a></li>
<li><a class="reference" href="#screen-and-vnc" id="id68" name="id68">screen and VNC</a></li>
<li><a class="reference" href="#trac" id="id69" name="id69">Trac</a></li>
</ul>
</li>
<li><a class="reference" href="#online-resources-for-python" id="id70" name="id70">Online Resources for Python</a></li>
<li><a class="reference" href="#wrapping-c-c-for-python" id="id71" name="id71">Wrapping C/C++ for Python</a><ul>
<li><a class="reference" href="#manual-wrapping" id="id72" name="id72">Manual wrapping</a></li>
<li><a class="reference" href="#wrapping-python-code-with-swig" id="id73" name="id73">Wrapping Python code with SWIG</a></li>
<li><a class="reference" href="#wrapping-c-code-with-pyrex" id="id74" name="id74">Wrapping C code with pyrex</a></li>
<li><a class="reference" href="#ctypes" id="id75" name="id75">ctypes</a></li>
<li><a class="reference" href="#sip" id="id76" name="id76">SIP</a></li>
<li><a class="reference" href="#boost-python" id="id77" name="id77">Boost.Python</a></li>
<li><a class="reference" href="#recommendations" id="id78" name="id78">Recommendations</a></li>
<li><a class="reference" href="#one-or-two-more-notes-on-wrapping" id="id79" name="id79">One or two more notes on wrapping</a></li>
</ul>
</li>
<li><a class="reference" href="#packages-for-multiprocessing" id="id80" name="id80">Packages for Multiprocessing</a><ul>
<li><a class="reference" href="#threading" id="id81" name="id81">threading</a></li>
<li><a class="reference" href="#writing-and-indicating-threadsafe-c-extensions" id="id82" name="id82">Writing (and indicating) threadsafe C extensions</a></li>
<li><a class="reference" href="#parallelpython" id="id83" name="id83">parallelpython</a></li>
<li><a class="reference" href="#rpyc" id="id84" name="id84">Rpyc</a></li>
<li><a class="reference" href="#pympi" id="id85" name="id85">pyMPI</a></li>
<li><a class="reference" href="#multitask" id="id86" name="id86">multitask</a></li>
</ul>
</li>
<li><a class="reference" href="#useful-packages" id="id87" name="id87">Useful Packages</a><ul>
<li><a class="reference" href="#subprocess" id="id88" name="id88">subprocess</a></li>
<li><a class="reference" href="#rpy" id="id89" name="id89">rpy</a></li>
<li><a class="reference" href="#matplotlib" id="id90" name="id90">matplotlib</a></li>
</ul>
</li>
<li><a class="reference" href="#idiomatic-python-take-3-new-style-classes" id="id91" name="id91">Idiomatic Python Take 3: new-style classes</a><ul>
<li><a class="reference" href="#managed-attributes" id="id92" name="id92">Managed attributes</a></li>
<li><a class="reference" href="#descriptors" id="id93" name="id93">Descriptors</a></li>
</ul>
</li>
<li><a class="reference" href="#gui-gossip" id="id94" name="id94">GUI Gossip</a></li>
<li><a class="reference" href="#python-3-0" id="id95" name="id95">Python 3.0</a></li>
</ul>
</div>
<div class="section">
<h1><a class="toc-backref" href="#id2" id="idiomatic-python" name="idiomatic-python">Idiomatic Python</a></h1>
<p>Extracts from <a class="reference" href="http://www.python.org/doc/Humor.html#zen">The Zen of Python</a> by Tim Peters:</p>
<blockquote>
<ul class="simple">
<li>Beautiful is better than ugly.</li>
<li>Explicit is better than implicit.</li>
<li>Simple is better than complex.</li>
<li>Readability counts.</li>
</ul>
</blockquote>
<p>(The whole Zen is worth reading...)</p>
<p>The first step in programming is getting stuff to work at all.</p>
<p>The next step in programming is getting stuff to work regularly.</p>
<p>The step after that is reusing code and designing for reuse.</p>
<p>Somewhere in there you will start writing idiomatic Python.</p>
<p>Idiomatic Python is what you write when the <em>only</em> thing you're
struggling with is the right way to solve <em>your</em> problem, and you're
not struggling with the programming language or some weird library
error or a nasty data retrieval issue or something else extraneous to
your real problem. The idioms you prefer may differ from the idioms I
prefer, but with Python there will be a fair amount of overlap,
because there is usually at most one obvious way to do every task.  (A
caveat: &quot;obvious&quot; is unfortunately the eye of the beholder, to some
extent.)</p>
<p>For example, let's consider the right way to keep track of the item number
while iterating over a list.  So, given a list z,</p>
<pre class="doctest-block">
&gt;&gt;&gt; z = [ 'a', 'b', 'c', 'd' ]
</pre>
<p>let's try printing out each item along with its index.</p>
<p>You could use a while loop:</p>
<pre class="doctest-block">
&gt;&gt;&gt; i = 0
&gt;&gt;&gt; while i &lt; len(z):
...    print i, z[i]
...    i += 1
0 a
1 b
2 c
3 d
</pre>
<p>or a for loop:</p>
<pre class="doctest-block">
&gt;&gt;&gt; for i in range(0, len(z)):
...    print i, z[i]
0 a
1 b
2 c
3 d
</pre>
<p>but I think the clearest option is to use <tt class="docutils literal"><span class="pre">enumerate</span></tt>:</p>
<pre class="doctest-block">
&gt;&gt;&gt; for i, item in enumerate(z):
...    print i, item
0 a
1 b
2 c
3 d
</pre>
<p>Why is this the clearest option?  Well, look at the ZenOfPython extract
above: it's explicit (we used <tt class="docutils literal"><span class="pre">enumerate</span></tt>); it's simple; it's readable;
and I would even argue that it's prettier than the while loop, if not
exactly &quot;beatiful&quot;.</p>
<p>Python provides this kind of simplicity in as many places as possible, too.
Consider file handles; did you know that they were iterable?</p>
<pre class="doctest-block">
&gt;&gt;&gt; for line in file('data/listfile.txt'):
...    print line.rstrip()
a
b
c
d
</pre>
<p>Where Python really shines is that this kind of simple idiom -- in
this case, iterables -- is very very easy not only to use but to
<em>construct</em> in your own code.  This will make your own code much more
reusable, while improving code readability dramatically.  And that's
the sort of benefit you will get from writing idiomatic Python.</p>
<div class="section">
<h2><a class="toc-backref" href="#id3" id="some-basic-data-types" name="some-basic-data-types">Some basic data types</a></h2>
<p>I'm sure you're all familiar with tuples, lists, and dictionaries, right?
Let's do a quick tour nonetheless.</p>
<p>'tuples' are all over the place.  For example, this code for swapping two
numbers implicitly uses tuples:</p>
<pre class="doctest-block">
&gt;&gt;&gt; a = 5
&gt;&gt;&gt; b = 6
&gt;&gt;&gt; a, b = b, a
&gt;&gt;&gt; print a == 6, b == 5
True True
</pre>
<p>That's about all I have to say about tuples.</p>
<p>I use lists and dictionaries <em>all the time</em>.  They're the two greatest
inventions of mankind, at least as far as Python goes.  With lists,
it's just easy to keep track of stuff:</p>
<pre class="doctest-block">
&gt;&gt;&gt; x = []
&gt;&gt;&gt; x.append(5)
&gt;&gt;&gt; x.extend([6, 7, 8])
&gt;&gt;&gt; x
[5, 6, 7, 8]
&gt;&gt;&gt; x.reverse()
&gt;&gt;&gt; x
[8, 7, 6, 5]
</pre>
<p>It's also easy to sort.  Consider this set of data:</p>
<pre class="doctest-block">
&gt;&gt;&gt; y = [ ('IBM', 5), ('Zil', 3), ('DEC', 18) ]
</pre>
<p>The <tt class="docutils literal"><span class="pre">sort</span></tt> method will run <tt class="docutils literal"><span class="pre">cmp</span></tt> on each of the tuples,
which sort on the first element of each tuple:</p>
<pre class="doctest-block">
&gt;&gt;&gt; y.sort()
&gt;&gt;&gt; y
[('DEC', 18), ('IBM', 5), ('Zil', 3)]
</pre>
<p>Often it's handy to sort tuples on a different tuple element, and there
are several ways to do that.  I prefer to provide my own sort method:</p>
<pre class="doctest-block">
&gt;&gt;&gt; def sort_on_second(a, b):
...   return cmp(a[1], b[1])
</pre>
<pre class="doctest-block">
&gt;&gt;&gt; y.sort(sort_on_second)
&gt;&gt;&gt; y
[('Zil', 3), ('IBM', 5), ('DEC', 18)]
</pre>
<p>Note that here I'm using the builtin <tt class="docutils literal"><span class="pre">cmp</span></tt> method (which is what <tt class="docutils literal"><span class="pre">sort</span></tt>
uses by default: <tt class="docutils literal"><span class="pre">y.sort()</span></tt> is equivalent to <tt class="docutils literal"><span class="pre">y.sort(cmp)</span></tt>) to do the
comparison of the second part of the tuple.</p>
<p>This kind of function is really handy for sorting dictionaries by
value, as I'll show you below.</p>
<p>(For a more in-depth discussion of sorting options, check out the
<a class="reference" href="http://wiki.python.org/moin/HowTo/Sorting">Sorting HowTo</a>.)</p>
<p>On to dictionaries!</p>
<p>Your basic dictionary is just a hash table that takes keys and returns
values:</p>
<pre class="doctest-block">
&gt;&gt;&gt; d = {}
&gt;&gt;&gt; d['a'] = 5
&gt;&gt;&gt; d['b'] = 4
&gt;&gt;&gt; d['c'] = 18
&gt;&gt;&gt; d
{'a': 5, 'c': 18, 'b': 4}
&gt;&gt;&gt; d['a']
5
</pre>
<p>You can also initialize a dictionary using the <tt class="docutils literal"><span class="pre">dict</span></tt> type to create
a dict object:</p>
<pre class="doctest-block">
&gt;&gt;&gt; e = dict(a=5, b=4, c=18)
&gt;&gt;&gt; e
{'a': 5, 'c': 18, 'b': 4}
</pre>
<p>Dictionaries have a few really neat features that I use pretty frequently.
For example, let's collect (key, value) pairs where we potentially have
multiple values for each key.  That is, given a file containing this data,</p>
<pre class="literal-block">
a 5
b 6
d 7
a 2
c 1
</pre>
<p>suppose we want to keep all the values?  If we just did it the simple way,</p>
<pre class="doctest-block">
&gt;&gt;&gt; d = {}
&gt;&gt;&gt; for line in file('data/keyvalue.txt'):
...   key, value = line.split()
...   d[key] = int(value)
</pre>
<p>we would lose all but the last value for each key:</p>
<pre class="doctest-block">
&gt;&gt;&gt; d
{'a': 2, 'c': 1, 'b': 6, 'd': 7}
</pre>
<p>You can collect <em>all</em> the values by using <tt class="docutils literal"><span class="pre">get</span></tt>:</p>
<pre class="doctest-block">
&gt;&gt;&gt; d = {}
&gt;&gt;&gt; for line in file('data/keyvalue.txt'):
...   key, value = line.split()
...   l = d.get(key, [])
...   l.append(int(value))
...   d[key] = l
&gt;&gt;&gt; d
{'a': [5, 2], 'c': [1], 'b': [6], 'd': [7]}
</pre>
<p>The key point here is that <tt class="docutils literal"><span class="pre">d.get(k,</span> <span class="pre">default)</span></tt> is equivalent to
<tt class="docutils literal"><span class="pre">d[k]</span></tt> if <tt class="docutils literal"><span class="pre">d[k]</span></tt> already exists; otherwise, it returns <tt class="docutils literal"><span class="pre">default</span></tt>.
So, the first time each key is used, <tt class="docutils literal"><span class="pre">l</span></tt> is set to an empty list;
the value is appended to this list, and then the value is set for that
key.</p>
<p>(There are tons of little tricks like the ones above, but these are the
ones I use the most; see the Python Cookbook for an endless supply!)</p>
<p>Now let's try combining some of the sorting stuff above with
dictionaries.  This time, our contrived problem is that we'd like to
sort the keys in the dictionary <tt class="docutils literal"><span class="pre">d</span></tt> that we just loaded, but rather
than sorting by key we want to sort by the sum of the values for each
key.</p>
<p>First, let's define a sort function:</p>
<pre class="doctest-block">
&gt;&gt;&gt; def sort_by_sum_value(a, b):
...    sum_a = sum(a[1])
...    sum_b = sum(b[1])
...    return cmp(sum_a, sum_b)
</pre>
<p>Now apply it to the dictionary items:</p>
<pre class="doctest-block">
&gt;&gt;&gt; items = d.items()
&gt;&gt;&gt; items
[('a', [5, 2]), ('c', [1]), ('b', [6]), ('d', [7])]
&gt;&gt;&gt; items.sort(sort_by_sum_value)
&gt;&gt;&gt; items
[('c', [1]), ('b', [6]), ('a', [5, 2]), ('d', [7])]
</pre>
<p>and voila, you have your list of keys sorted by summed values!</p>
<p>As I said, there are tons and tons of cute little tricks that you can
do with dictionaries.  I think they're incredibly powerful.</p>
<!-- @CTB invert dictionary -->
</div>
<div class="section">
<h2><a class="toc-backref" href="#id4" id="list-comprehensions" name="list-comprehensions">List comprehensions</a></h2>
<p>List comprehensions are neat little constructs that will shorten your
lines of code considerably.  Here's an example that constructs a list
of squares between 0 and 4:</p>
<pre class="doctest-block">
&gt;&gt;&gt; z = [ i**2 for i in range(0, 5) ]
&gt;&gt;&gt; z
[0, 1, 4, 9, 16]
</pre>
<p>You can also add in conditionals, like requiring only even numbers:</p>
<pre class="doctest-block">
&gt;&gt;&gt; z = [ i**2 for i in range(0, 10) if i % 2 == 0 ]
&gt;&gt;&gt; z
[0, 4, 16, 36, 64]
</pre>
<p>The general form is</p>
<pre class="literal-block">
[ expression for var in list if conditional ]
</pre>
<p>so pretty much anything you want can go in <tt class="docutils literal"><span class="pre">expression</span></tt> and <tt class="docutils literal"><span class="pre">conditional</span></tt>.</p>
<p>I find list comprehensions to be very useful for both file parsing and
for simple math.  Consider a file containing data and comments:</p>
<pre class="literal-block">
# this is a comment or a header
1
# another comment
2
</pre>
<p>where you want to read in the numbers only:</p>
<pre class="doctest-block">
&gt;&gt;&gt; data = [ int(x) for x in open('data/commented-data.txt') if x[0] != '#' ]
&gt;&gt;&gt; data
[1, 2]
</pre>
<p>This is short, simple, and very explicit!</p>
<p>For simple math, suppose you need to calculate the average and stddev of
some numbers.  Just use a list comprehension:</p>
<pre class="doctest-block">
&gt;&gt;&gt; import math
&gt;&gt;&gt; data = [ 1, 2, 3, 4, 5 ]
&gt;&gt;&gt; average = sum(data) / float(len(data))
&gt;&gt;&gt; stddev = sum([ (x - average)**2 for x in data ]) / float(len(data))
&gt;&gt;&gt; stddev = math.sqrt(stddev)
&gt;&gt;&gt; print average, '+/-', stddev
3.0 +/- 1.41421356237
</pre>
<p>Oh, and one rule of thumb: if your list comprehension is longer than
one line, change it to a for loop; it will be easier to read, and easier
to understand.</p>
</div>
<div class="section">
<h2><a class="toc-backref" href="#id5" id="building-your-own-types" name="building-your-own-types">Building your own types</a></h2>
<p>Most people should be pretty familiar with basic classes.</p>
<pre class="doctest-block">
&gt;&gt;&gt; class A:
...   def __init__(self, item):
...      self.item = item
...   def hello(self):
...      print 'hello,', self.item
</pre>
<pre class="doctest-block">
&gt;&gt;&gt; x = A('world')
&gt;&gt;&gt; x.hello()
hello, world
</pre>
<p>There are a bunch of neat things you can do with classes, but one of
the neatest is building new types that can be used with standard
Python list/dictionary idioms.</p>
<p>For example, let's consider a basic binning class.</p>
<pre class="doctest-block">
&gt;&gt;&gt; class Binner:
...   def __init__(self, binwidth, binmax):
...     self.binwidth, self.binmax = binwidth, binmax
...     nbins = int(binmax / float(binwidth) + 1)
...     self.bins = [0] * nbins
...
...   def add(self, value):
...     bin = value / self.binwidth
...     self.bins[bin] += 1
</pre>
<p>This behaves as you'd expect:</p>
<pre class="doctest-block">
&gt;&gt;&gt; binner = Binner(5, 20)
&gt;&gt;&gt; for i in range(0,20):
...   binner.add(i)
&gt;&gt;&gt; binner.bins
[5, 5, 5, 5, 0]
</pre>
<p>...but wouldn't it be nice to be able to write this?</p>
<pre class="literal-block">
for i in range(0, len(binner)):
   print i, binner[i]
</pre>
<p>or even this?</p>
<pre class="literal-block">
for i, bin in enumerate(binner):
   print i, bin
</pre>
<p>This is actually quite easy, if you make the <tt class="docutils literal"><span class="pre">Binner</span></tt> class look like a
list by adding two special functions:</p>
<pre class="doctest-block">
&gt;&gt;&gt; class Binner:
...   def __init__(self, binwidth, binmax):
...     self.binwidth, self.binmax = binwidth, binmax
...     nbins = int(binmax / float(binwidth) + 1)
...     self.bins = [0] * nbins
...
...   def add(self, value):
...     bin = value / self.binwidth
...     self.bins[bin] += 1
...
...   def __getitem__(self, index):
...     return self.bins[index]
...
...   def __len__(self):
...     return len(self.bins)
</pre>
<pre class="doctest-block">
&gt;&gt;&gt; binner = Binner(5, 20)
&gt;&gt;&gt; for i in range(0,20):
...   binner.add(i)
</pre>
<p>and now we can treat <tt class="docutils literal"><span class="pre">Binner</span></tt> objects as normal lists:</p>
<pre class="doctest-block">
&gt;&gt;&gt; for i in range(0, len(binner)):
...   print i, binner[i]
0 5
1 5
2 5
3 5
4 0
</pre>
<pre class="doctest-block">
&gt;&gt;&gt; for n in binner:
...   print n
5
5
5
5
0
</pre>
<p>In the case of <tt class="docutils literal"><span class="pre">len(binner)</span></tt>, Python knows to use the special method
<tt class="docutils literal"><span class="pre">__len__</span></tt>, and likewise <tt class="docutils literal"><span class="pre">binner[i]</span></tt> just calls <tt class="docutils literal"><span class="pre">__getitem__(i)</span></tt>.</p>
<p>The second case involves a bit more implicit magic.  Here, Python figures
out that <tt class="docutils literal"><span class="pre">Binner</span></tt> can act like a list and simply calls the right functions
to retrieve the information.</p>
<p>Note that making your own read-only dictionaries is pretty simple, too:
just provide the <tt class="docutils literal"><span class="pre">__getitem__</span></tt> function, which is called for non-integer
values as well:</p>
<pre class="doctest-block">
&gt;&gt;&gt; class SillyDict:
...    def __getitem__(self, key):
...       print 'key is', key
...       return key
&gt;&gt;&gt; sd = SillyDict()
&gt;&gt;&gt; x = sd['hello, world']
key is hello, world
&gt;&gt;&gt; x
'hello, world'
</pre>
<p>You can also write your own mutable types, e.g.</p>
<pre class="doctest-block">
&gt;&gt;&gt; class SillyDict:
...   def __setitem__(self, key, value):
...      print 'setting', key, 'to', value
&gt;&gt;&gt; sd = SillyDict()
&gt;&gt;&gt; sd[5] = 'world'
setting 5 to world
</pre>
<p>but I have found this to be less useful in my own code, where I'm
usually writing special objects like the <tt class="docutils literal"><span class="pre">Binner</span></tt> type above: I
prefer to specify my own methods for putting information <em>into</em> the
object type, because it reminds me that it is not a generic Python
list or dictionary.  However, the use of <tt class="docutils literal"><span class="pre">__getitem__</span></tt> (and some of
the iterator and generator features I discuss below) can make code <em>much</em>
more readable, and so I use them whenever I think the meaning will be
unambiguous.   For example, with the <tt class="docutils literal"><span class="pre">Binner</span></tt> type, the purpose of
<tt class="docutils literal"><span class="pre">__getitem__</span></tt> and <tt class="docutils literal"><span class="pre">__len__</span></tt> is not very ambiguous, while the
purpose of a <tt class="docutils literal"><span class="pre">__setitem__</span></tt> function (to support <tt class="docutils literal"><span class="pre">binner[x]</span> <span class="pre">=</span> <span class="pre">y</span></tt>)
would be unclear.</p>
<p>Overall, the creation of your own custom list and dict types is one
way to make reusable code that will fit nicely into Python's natural
idioms.  In turn, this can make your code look much simpler and feel
much cleaner.  The risk, of course, is that you will also make your
code harder to understand and (if you're not careful) harder to debug.
Mediating between these options is mostly a matter of experience.</p>
<!-- @CTB __getattr__ trick -->
</div>
<div class="section">
<h2><a class="toc-backref" href="#id6" id="iterators" name="iterators">Iterators</a></h2>
<p>Iterators are another built-in Python feature; unlike the list and
dict types we discussed above, an iterator isn't really a <em>type</em>, but
a <em>protocol</em>.  This just means that Python agrees to respect anything
that supports a particular set of methods as if it were an iterator.
(These protocols appear everywhere in Python; we were taking advantage
of the mapping and sequence protocols above, when we defined
<tt class="docutils literal"><span class="pre">__getitem__</span></tt> and <tt class="docutils literal"><span class="pre">__len__</span></tt>, respectively.)</p>
<p>Iterators are more general versions of the sequence protocol; here's an
example:</p>
<pre class="doctest-block">
&gt;&gt;&gt; class SillyIter:
...   i = 0
...   n = 5
...   def __iter__(self):
...      return self
...   def next(self):
...      self.i += 1
...      if self.i &gt; self.n:
...         raise StopIteration
...      return self.i
</pre>
<pre class="doctest-block">
&gt;&gt;&gt; si = SillyIter()
&gt;&gt;&gt; for i in si:
...   print i
1
2
3
4
5
</pre>
<p>Here, <tt class="docutils literal"><span class="pre">__iter__</span></tt> just returns <tt class="docutils literal"><span class="pre">self</span></tt>, an object that has the
function <tt class="docutils literal"><span class="pre">next()</span></tt>, which (when called) either returns a value or
raises a StopIteration exception.</p>
<p>We've actually already met several iterators in disguise; in particular,
<tt class="docutils literal"><span class="pre">enumerate</span></tt> is an iterator.  To drive home the point, here's a simple
reimplementation of <tt class="docutils literal"><span class="pre">enumerate</span></tt>:</p>
<pre class="doctest-block">
&gt;&gt;&gt; class my_enumerate:
...   def __init__(self, some_iter):
...      self.some_iter = iter(some_iter)
...      self.count = -1
...
...   def __iter__(self):
...      return self
...
...   def next(self):
...      val = self.some_iter.next()
...      self.count += 1
...      return self.count, val
&gt;&gt;&gt; for n, val in my_enumerate(['a', 'b', 'c']):
...   print n, val
0 a
1 b
2 c
</pre>
<p>You can also iterate through an iterator the &quot;old-fashioned&quot; way:</p>
<pre class="doctest-block">
&gt;&gt;&gt; some_iter = iter(['a', 'b', 'c'])
&gt;&gt;&gt; while 1:
...   try:
...      print some_iter.next()
...   except StopIteration:
...      break
a
b
c
</pre>
<p>but that would be silly in most situations! I use this if I just want
to get the first value or two from an iterator.</p>
<p>With iterators, one thing to watch out for is the return of <tt class="docutils literal"><span class="pre">self</span></tt> from
the <tt class="docutils literal"><span class="pre">__iter__</span></tt> function.  You can all too easily write an iterator that
isn't as re-usable as you think it is.  For example, suppose you had
the following class:</p>
<pre class="doctest-block">
&gt;&gt;&gt; class MyTrickyIter:
...   def __init__(self, thelist):
...      self.thelist = thelist
...      self.index = -1
...
...   def __iter__(self):
...      return self
...
...   def next(self):
...      self.index += 1
...      if self.index &lt; len(self.thelist):
...         return self.thelist[self.index]
...      raise StopIteration
</pre>
<p>This works just like you'd expect as long as you create a new object each
time:</p>
<pre class="doctest-block">
&gt;&gt;&gt; for i in MyTrickyIter(['a', 'b']):
...   for j in MyTrickyIter(['a', 'b']):
...      print i, j
a a
a b
b a
b b
</pre>
<p>but it will break if you create the object just once:</p>
<pre class="doctest-block">
&gt;&gt;&gt; mi = MyTrickyIter(['a', 'b'])
&gt;&gt;&gt; for i in mi:
...   for j in mi:
...      print i, j
a b
</pre>
<p>because self.index is incremented in each loop.</p>
</div>
<div class="section">
<h2><a class="toc-backref" href="#id7" id="generators" name="generators">Generators</a></h2>
<p>Generators are a Python implementation of <a class="reference" href="http://en.wikipedia.org/wiki/Coroutine">coroutines</a>.  Essentially, they're
functions that let you suspend execution and return a result:</p>
<pre class="doctest-block">
&gt;&gt;&gt; def g():
...   for i in range(0, 5):
...      yield i**2
&gt;&gt;&gt; for i in g():
...    print i
0
1
4
9
16
</pre>
<p>You could do this with a list just as easily, of course:</p>
<pre class="doctest-block">
&gt;&gt;&gt; def h():
...   return [ x ** 2 for x in range(0, 5) ]
&gt;&gt;&gt; for i in h():
...    print i
0
1
4
9
16
</pre>
<p>But you can do things with generators that you couldn't do with finite
lists.  Consider two full implementation of Eratosthenes' Sieve for
finding prime numbers, below.</p>
<p>First, let's define some boilerplate code that can be used by either
implementation:</p>
<pre class="doctest-block">
&gt;&gt;&gt; def divides(primes, n):
...   for trial in primes:
...      if n % trial == 0: return True
...   return False
</pre>
<p>Now, let's write a simple sieve with a generator:</p>
<pre class="doctest-block">
&gt;&gt;&gt; def prime_sieve():
...    p, current = [], 1
...    while 1:
...        current += 1
...        if not divides(p, current): # if any previous primes divide, cancel
...            p.append(current)           # this is prime! save &amp; return
...            yield current
</pre>
<p>This implementation will find (within the limitations of Python's math
functions) all prime numbers; the programmer has to stop it herself:</p>
<pre class="doctest-block">
&gt;&gt;&gt; for i in prime_sieve():
...    print i
...    if i &gt; 10:
...        break
2
3
5
7
11
</pre>
<p>So, here we're using a generator to implement the generation of an
infinite series with a single function definition.  To do the equivalent
with an iterator would require a class, so that the object instance can
hold the variables:</p>
<pre class="doctest-block">
&gt;&gt;&gt; class iterator_sieve:
...    def __init__(self):
...       self.p, self.current = [], 1
...    def __iter__(self):
...       return self
...    def next(self):
...       while 1:
...          self.current = self.current + 1
...          if not divides(self.p, self.current):
...             self.p.append(self.current)
...             return self.current
</pre>
<pre class="doctest-block">
&gt;&gt;&gt; for i in iterator_sieve():
...    print i
...    if i &gt; 10:
...        break
2
3
5
7
11
</pre>
<p>It is also <em>much</em> easier to write routines like <tt class="docutils literal"><span class="pre">enumerate</span></tt> as a
generator than as an iterator:</p>
<pre class="doctest-block">
&gt;&gt;&gt; def gen_enumerate(some_iter):
...   count = 0
...   for val in some_iter:
...      yield count, val
...      count += 1
</pre>
<pre class="doctest-block">
&gt;&gt;&gt; for n, val in gen_enumerate(['a', 'b', 'c']):
...   print n, val
0 a
1 b
2 c
</pre>
<p>Abstruse note: we don't even have to catch <tt class="docutils literal"><span class="pre">StopIteration</span></tt> here, because
the for loop simply ends when <tt class="docutils literal"><span class="pre">some_iter</span></tt> is done!</p>
</div>
<div class="section">
<h2><a class="toc-backref" href="#id8" id="assert" name="assert">assert</a></h2>
<p>One of the most underused keywords in Python is <tt class="docutils literal"><span class="pre">assert</span></tt>.  Assert is
pretty simple: it takes a boolean, and if the boolean evaluates to
False, it fails (by raising an AssertionError exception).  <tt class="docutils literal"><span class="pre">assert</span> <span class="pre">True</span></tt>
is a no-op.</p>
<pre class="doctest-block">
&gt;&gt;&gt; assert True
&gt;&gt;&gt; assert False
Traceback (most recent call last):
   ...
AssertionError
</pre>
<p>You can also put an optional message in:</p>
<pre class="doctest-block">
&gt;&gt;&gt; assert False, &quot;you can't do that here!&quot;
Traceback (most recent call last):
   ...
AssertionError: you can't do that here!
</pre>
<p><tt class="docutils literal"><span class="pre">assert</span></tt> is very, very useful for making sure that code is behaving
according to your expectations during development.  Worried that
you're getting an empty list?  <tt class="docutils literal"><span class="pre">assert</span> <span class="pre">len(x)</span></tt>.  Want to make sure
that a particular return value is not None?  <tt class="docutils literal"><span class="pre">assert</span> <span class="pre">retval</span> <span class="pre">is</span> <span class="pre">not</span>
<span class="pre">None</span></tt>.</p>
<p>Also note that 'assert' statements are removed from optimized code, so only
use them to conditions related to actual development, and make sure that
the statement you're evaluating has no side effects.  For example,</p>
<pre class="doctest-block">
&gt;&gt;&gt; a = 1
&gt;&gt;&gt; def check_something():
...   global a
...   a = 5
...   return True
&gt;&gt;&gt; assert check_something()
</pre>
<p>will behave differently when run under optimization than when run without
optimization, because the <tt class="docutils literal"><span class="pre">assert</span></tt> line will be removed completely from
optimized code.</p>
<p>If you need to raise an exception in production code, see below.  The
quickest and dirtiest way is to just &quot;raise Exception&quot;, but that's kind
of non-specific ;).</p>
</div>
<div class="section">
<h2><a class="toc-backref" href="#id9" id="conclusions" name="conclusions">Conclusions</a></h2>
<p>Use of common Python idioms -- both in your python code and for your
new types -- leads to short, sweet programs.</p>
</div>
</div>
<div class="section">
<h1><a class="toc-backref" href="#id10" id="structuring-testing-and-maintaining-python-programs" name="structuring-testing-and-maintaining-python-programs">Structuring, Testing, and Maintaining Python Programs</a></h1>
<p>Python is really the first programming language in which I started
re-using code significantly.  In part, this is because it is rather
easy to compartmentalize functions and classes in Python.  Something
else that Python makes relatively easy is building testing into your
program structure.  Combined, reusability and testing can have a huge
effect on maintenance.</p>
<div class="section">
<h2><a class="toc-backref" href="#id11" id="programming-for-reusability" name="programming-for-reusability">Programming for reusability</a></h2>
<p>It's difficult to come up with any hard and fast rules for programming
for reusability, but my main rules of thumb are: don't plan too much,
and don't hesitate to refactor your code. <a class="footnote-reference" href="#refactor" id="id1" name="id1">[1]</a>.</p>
<p>In any project, you will write code that
you want to re-use in a slightly different context.  It will often be
easiest to cut and paste this code rather than to copy the module it's
in -- but try to resist this temptation a bit, and see if you can make
the code work for both uses, and then use it in both places.</p>
<table class="docutils footnote" frame="void" id="refactor" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id1" name="refactor">[1]</a></td><td>If you haven't read Martin Fowler's <strong>Refactoring</strong>, do
so -- it describes how to incrementally make your code better.
I'll discuss it some more in the context of testing, below.</td></tr>
</tbody>
</table>
</div>
<div class="section">
<h2><a class="toc-backref" href="#id12" id="modules-and-scripts" name="modules-and-scripts">Modules and scripts</a></h2>
<p>The organization of your code source files can help or hurt you with
code re-use.</p>
<p>Most people start their Python programming out by putting everything in
a script:</p>
<pre class="literal-block">
calc-squares.py:
  #! /usr/bin/env python
  for i in range(0, 10):
     print i**2
</pre>
<p>This is great for experimenting, but you can't re-use this code at all!</p>
<p>(UNIX folk: note the use of <tt class="docutils literal"><span class="pre">#!</span> <span class="pre">/usr/bin/env</span> <span class="pre">python</span></tt>, which tells UNIX
to execute this script using whatever <tt class="docutils literal"><span class="pre">python</span></tt> program is first in your
path.  This is more portable than putting <tt class="docutils literal"><span class="pre">#!</span> <span class="pre">/usr/local/bin/python</span></tt> or
<tt class="docutils literal"><span class="pre">#!</span> <span class="pre">/usr/bin/python</span></tt> in your code, because not everyone puts python in
the same place.)</p>
<p>Back to reuse.  What about this?</p>
<pre class="literal-block">
calc-squares.py:
  #! /usr/bin/env python
  def squares(start, stop):
     for i in range(start, stop):
        print i**2

  squares(0, 10)
</pre>
<p>I think that's a bit better for re-use -- you've made <tt class="docutils literal"><span class="pre">squares</span></tt>
flexible and re-usable -- but there are two mechanistic problems.
First, it's named <tt class="docutils literal"><span class="pre">calc-squares.py</span></tt>, which means it can't readily be
imported.  (Import filenames have to be valid Python names, of
course!)  And, second, were it importable, it would execute <tt class="docutils literal"><span class="pre">squares(0,</span> <span class="pre">10)</span></tt>
on import - hardly what you want!</p>
<p>To fix the first, just change the name:</p>
<pre class="literal-block">
calc_squares.py:
  #! /usr/bin/env python
  def squares(start, stop):
    for i in range(start, stop):
        print i**2

  squares(0, 10)
</pre>
<p>Good, but now if you do <tt class="docutils literal"><span class="pre">import</span> <span class="pre">calc_squares</span></tt>, the <tt class="docutils literal"><span class="pre">squares(0,</span> <span class="pre">10)</span></tt> code
will still get run!  There are a couple of ways to deal with this.  The first
is to look at the module name: if it's <tt class="docutils literal"><span class="pre">calc_squares</span></tt>, then the module is
being imported, while if it's <tt class="docutils literal"><span class="pre">__main__</span></tt>, then the module is being run as
a script:</p>
<pre class="literal-block">
calc_squares.py:
  #! /usr/bin/env python
  def squares(start, stop):
    for i in range(start, stop):
       print i**2

  if __name__ == '__main__':
    squares(0, 10)
</pre>
<p>Now, if you run <tt class="docutils literal"><span class="pre">calc_squares.py</span></tt> directly, it will run <tt class="docutils literal"><span class="pre">squares(0,</span> <span class="pre">10)</span></tt>;
if you import it, it will simply define the <tt class="docutils literal"><span class="pre">squares</span></tt> function and leave
it at that.  This is probably the most standard way of doing it.</p>
<p>I actually prefer a different technique, because of my fondness for testing.
(I also think this technique lends itself to reusability, though.)  I
would actually write two files:</p>
<pre class="literal-block">
squares.py:
  def squares(start, stop):
    for i in range(start, stop):
       print i**2

  if __name__ == `__main__`:
    # ...run automated tests...

calc-squares:
  #! /usr/bin/env python
  import squares
  squares.squares(0, 10)
</pre>
<p>A few notes -- first, this is eminently reusable code, because
<tt class="docutils literal"><span class="pre">squares.py</span></tt> is completely separate from the context-specific call.
Second, you can look at the directory listing in an instant and see
that <tt class="docutils literal"><span class="pre">squares.py</span></tt> is probably a library, while <tt class="docutils literal"><span class="pre">calc-squares</span></tt> must
be a script, because the latter cannot be imported.  Third, you can add
automated tests to <tt class="docutils literal"><span class="pre">squares.py</span></tt> (as described below), and run them
simply by running <tt class="docutils literal"><span class="pre">python</span> <span class="pre">squares.py</span></tt>.  Fourth, you can add script-specific
code such as command-line argument handling to the script, and keep it
separate from your data handling and algorithm code.</p>
</div>
<div class="section">
<h2><a class="toc-backref" href="#id13" id="packages" name="packages">Packages</a></h2>
<p>A Python package is a directory full of Python modules containing a
special file, <tt class="docutils literal"><span class="pre">__init__.py</span></tt>, that tells Python that the directory is
a package.  Packages are for collections of library code that are too
big to fit into single files, or that have some logical substructure
(e.g. a central library along with various utility functions that all
interact with the central library).</p>
<p>For an example, look at this directory tree:</p>
<pre class="literal-block">
package/
  __init__.py        -- contains functions a(), b()
  other.py           -- contains function c()
  subdir/
     __init__.py     -- contains function d()
</pre>
<p>From this directory tree, you would be able to access the functions like
so:</p>
<pre class="literal-block">
import package
package.a()
package.b()

import package.other
package.other.c()

import package.subdir
package.subdir.d()
</pre>
<p>Note that <tt class="docutils literal"><span class="pre">__init__.py</span></tt> is just another Python file; there's nothing
special about it except for the name, which tells Python that the
directory is a package directory.  <tt class="docutils literal"><span class="pre">__init__.py</span></tt> is the only code
executed on import, so if you want names and symbols from other
modules to be accessible at the package top level, you have to import
or create them in <tt class="docutils literal"><span class="pre">__init__.py</span></tt>.</p>
<p>There are two ways to use packages: you can treat them as a convenient
code organization technique, and make most of the functions or classes
available at the top level; or you can use them as a library
hierarchy.  In the first case you would make all of the names above
available at the top level:</p>
<pre class="literal-block">
package/__init__.py:
  from other import c
  from subdir import d
  ...
</pre>
<p>which would let you do this:</p>
<pre class="literal-block">
import package
package.a()
package.b()
package.c()
package.d()
</pre>
<p>That is, the names of the functions would all be immediately available at
the top level of the package, but the implementations would be spread out
among the different files and directories.  I personally prefer this because
I don't have to remember as much ;).  The down side is that everything gets
imported all at once, which (especially for large bodies of code) may be
slow and memory intensive if you only need a few of the functions.</p>
<p>Alternatively, if you wanted to keep the library hierarchy, just leave out
the top-level imports.  The advantage here is that you only import the
names you need; however, you need to remember more.</p>
<p>Some people are fond of package trees, but I've found that hierarchies
of packages more than two deep are annoying to develop on: you spend a
lot of your time browsing around between directories, trying to figure
out <em>exactly</em> which function you need to use and what it's named.
(Your mileage may vary.)  I think this is one of the main reasons why
the Python stdlib looks so big, because most of the packages are
top-level.</p>
<p>One final note: you can restrict what objects are exported from a module
or package by listing the names in the <tt class="docutils literal"><span class="pre">__all__</span></tt> variable.  So, if
you had a module <tt class="docutils literal"><span class="pre">some_mod.py</span></tt> that contained this code:</p>
<pre class="literal-block">
some_mod.py:
  __all__ = ['fn1']

  def fn1(...):
      ...

  def fn2(...):
      ...
</pre>
<p>then only 'some_mod.fn1()' would be available on import.  This is a
good way to cut down on &quot;namespace pollution&quot; -- the presence of
&quot;private&quot; objects and code in imported modules -- which in turn makes
introspection useful.</p>
</div>
<div class="section">
<h2><a class="toc-backref" href="#id14" id="a-short-digression-naming-and-formatting" name="a-short-digression-naming-and-formatting">A short digression: naming and formatting</a></h2>
<p>You may have noticed that a lot of Python code looks pretty similar --
this is because there's an &quot;official&quot; style guide for Python, called
<a class="reference" href="http://www.python.org/dev/peps/pep-0008/">PEP 8</a>.  It's worth a quick
skim, and an occasional deeper read for some sections.</p>
<p>Here are a few tips that will make your code look internally
consistent, if you don't already have a coding style of your own:</p>
<blockquote>
<ul>
<li><p class="first">use four spaces (NOT a tab) for each indentation level;</p>
</li>
<li><dl class="first docutils">
<dt>use lowercase, _-separated names for module and function names, e.g.</dt>
<dd><p class="first last"><tt class="docutils literal"><span class="pre">my_module</span></tt>;</p>
</dd>
</dl>
</li>
<li><p class="first">use CapsWord style to name classes, e.g. <tt class="docutils literal"><span class="pre">MySpecialClass</span></tt>;</p>
</li>
<li><dl class="first docutils">
<dt>use '_'-prefixed names to indicate a &quot;private&quot; variable that should</dt>
<dd><p class="first last">not be used outside this module, , e.g. <tt class="docutils literal"><span class="pre">_some_private_variable</span></tt>;</p>
</dd>
</dl>
</li>
</ul>
</blockquote>
</div>
<div class="section">
<h2><a class="toc-backref" href="#id15" id="another-short-digression-docstrings" name="another-short-digression-docstrings">Another short digression: docstrings</a></h2>
<p>Docstrings are strings of text attached to Python objects like
modules, classes, and methods/functions.  They can be used to provide
human-readable help when building a library of code.  &quot;Good&quot; docstring
coding is used to provide additional information about functionality
beyond what can be discovered automatically by introspection; compare</p>
<pre class="literal-block">
def is_prime(x):
    &quot;&quot;&quot;
    is_prime(x) -&gt; true/false.  Determines whether or not x is prime,
    and return true or false.
    &quot;&quot;&quot;
</pre>
<p>versus</p>
<pre class="literal-block">
def is_prime(x):
    &quot;&quot;&quot;
    Returns true if x is prime, false otherwise.

    is_prime() uses the Bernoulli-Schmidt formalism for figuring out
    if x is prime.  Because the BS form is stochastic and hysteretic,
    multiple calls to this function will be increasingly accurate.
    &quot;&quot;&quot;
</pre>
<p>The top example is good (documentation is good!), but the bottom
example is better, for a few reasons.  First, it is not redundant:
the arguments to <tt class="docutils literal"><span class="pre">is_prime</span></tt> are discoverable by introspection and
don't need to be specified.  Second, it's summarizable: the first line
stands on its own, and people who are interested in more detail can read
on.  This enables certain document extraction tools to do a better job.</p>
<p>For more on docstrings, see <a class="reference" href="http://www.python.org/dev/peps/pep-0257/">PEP 257</a>.</p>
</div>
<div class="section">
<h2><a class="toc-backref" href="#id16" id="sharing-data-between-code" name="sharing-data-between-code">Sharing data between code</a></h2>
<p>There are three levels at which data can be shared between Python
code: module globals, class attributes, and object attributes.  You
can also sneak data into functions by dynamically defining a function
within another scope, and/or binding them to keyword arguments.</p>
</div>
<div class="section">
<h2><a class="toc-backref" href="#id17" id="scoping-a-digression" name="scoping-a-digression">Scoping: a digression</a></h2>
<p>Just to make sure we're clear on scoping, here are a few simple
examples.  In this first example, f() gets x from the module
namespace.</p>
<pre class="doctest-block">
&gt;&gt;&gt; x = 1
&gt;&gt;&gt; def f():
...   print x
&gt;&gt;&gt; f()
1
</pre>
<p>In this second example, f() overrides x, but only within the namespace
in f().</p>
<pre class="doctest-block">
&gt;&gt;&gt; x = 1
&gt;&gt;&gt; def f():
...   x = 2
...   print x
&gt;&gt;&gt; f()
2
&gt;&gt;&gt; print x
1
</pre>
<p>In this third example, g() overrides x, and h() obtains x from within g(),
because h() was <em>defined</em> within g():</p>
<pre class="doctest-block">
&gt;&gt;&gt; x = 1
</pre>
<pre class="doctest-block">
&gt;&gt;&gt; def outer():
...    x = 2
...
...    def inner():
...       print x
...
...    return inner
</pre>
<pre class="doctest-block">
&gt;&gt;&gt; inner = outer()
&gt;&gt;&gt; inner()
2
</pre>
<p>In all cases, without a <tt class="docutils literal"><span class="pre">global</span></tt> declaration, assignments will
simply create a new local variable of that name, and not modify the
value in any other scope:</p>
<pre class="doctest-block">
&gt;&gt;&gt; x = 1
&gt;&gt;&gt; def outer():
...    x = 2
...
...    def inner():
...       x = 3
...
...    inner()
...
...    print x
&gt;&gt;&gt; outer()
2
</pre>
<p>However, <em>with</em> a <tt class="docutils literal"><span class="pre">global</span></tt> definition, the outermost scope is used:</p>
<pre class="doctest-block">
&gt;&gt;&gt; x = 1
&gt;&gt;&gt; def outer():
...    x = 2
...
...    def inner():
...       global x
...       x = 3
...
...    inner()
...
...    print x
&gt;&gt;&gt; outer()
2
&gt;&gt;&gt; print x
3
</pre>
<p>I generally suggest avoiding scope trickery as much as possible, in
the interests of readability.  There are two common patterns that I
use when I <em>have</em> to deal with scope issues.</p>
<p>First, module globals are sometimes necessary.  For one such case,
imagine that you have a centralized resource that you must initialize
precisely once, and you have a number of functions that depend on that
resource.  Then you can use a module global to keep track of the
initialization state.  Here's a (contrived!) example for a random
number generator that initializes the random number seed precisely
once:</p>
<pre class="literal-block">
_initialized = False
def init():
  global _initialized
  if not _initialized:
      import time
      random.seed(time.time())
      _initialized = True

def randint(start, stop):
  init()
  ...
</pre>
<p>This code ensures that the random number seed is initialized only once by
making use of the <tt class="docutils literal"><span class="pre">_initialized</span></tt> module global.  A few points, however:</p>
<blockquote>
<ul class="simple">
<li>this code is not threadsafe.  If it was really important that the
resource be initialized precisely once, you'd need to use thread locking.
Otherwise two functions could call <tt class="docutils literal"><span class="pre">randint()</span></tt> at the same time and
both could get past the <tt class="docutils literal"><span class="pre">if</span></tt> statement.</li>
<li>the module global code is very isolated and its use is very clear.
Generally I recommend having only one or two functions that access the
module global, so that if I need to change its use I don't have to
understand a lot of code.</li>
</ul>
</blockquote>
<p>The other &quot;scope trickery&quot; that I sometimes engage in is passing data into
dynamically generated functions.  Consider a situation where you have to
use a callback API: that is, someone has given you a library function that
will call your own code in certain situations. For our example, let's look at
the <tt class="docutils literal"><span class="pre">re.sub</span></tt> function that comes with Python, which takes a callback
function to apply to each match.</p>
<p>Here's a callback function that uppercases words:</p>
<pre class="doctest-block">
&gt;&gt;&gt; def replace(m):
...   match = m.group()
...   print 'replace is processing:', match
...   return match.upper()
&gt;&gt;&gt; s = &quot;some string&quot;
</pre>
<pre class="doctest-block">
&gt;&gt;&gt; import re
&gt;&gt;&gt; print re.sub('\\S+', replace, s)
replace is processing: some
replace is processing: string
SOME STRING
</pre>
<p>What's happening here is that the <tt class="docutils literal"><span class="pre">replace</span></tt> function is called each
time the regular expression '\S+' (a set of non-whitespace characters)
is matched.  The matching substring is replaced by whatever the
function returns.</p>
<p>Now let's imagine a situation where we want to pass information into
<tt class="docutils literal"><span class="pre">replace</span></tt>; for example, we want to process only words that match
in a dictionary.  (I <em>told</em> you it was contrived!)  We could simply rely
on scoping:</p>
<pre class="doctest-block">
&gt;&gt;&gt; d = { 'some' : True, 'string' : False }
&gt;&gt;&gt; def replace(m):
...   match = m.group()
...   if match in d and d[match]:
...      return match.upper()
...   return match
</pre>
<pre class="doctest-block">
&gt;&gt;&gt; print re.sub('\\S+', replace, s)
SOME string
</pre>
<p>but I would argue against it on the grounds of readability: passing
information implicitly between scopes is bad.  (At this point advanced
Pythoneers might sneer at me, because scoping is natural to Python,
but nuts to them: readability and transparency is also very
important.)  You <em>could</em> also do it this way:</p>
<pre class="doctest-block">
&gt;&gt;&gt; d = { 'some' : True, 'string' : False }
&gt;&gt;&gt; def replace(m, replace_dict=d):             # &lt;-- explicit declaration
...   match = m.group()
...   if match in replace_dict and replace_dict[match]:
...      return match.upper()
...   return match
</pre>
<pre class="doctest-block">
&gt;&gt;&gt; print re.sub('\\S+', replace, s)
SOME string
</pre>
<p>The idea is to use keyword arguments on the function to pass in required
information, thus making the information passing explicit.</p>
</div>
<div class="section">
<h2><a class="toc-backref" href="#id18" id="back-to-sharing-data" name="back-to-sharing-data">Back to sharing data</a></h2>
<p>I started discussing scope in the context of sharing data, but we got
a bit sidetracked from data sharing.  Let's get back to that now.</p>
<p>The key to thinking about data sharing in the context of code reuse
is to think about how that data will be used.</p>
<p>If you use a module global, then any code in that module has access to
that global.</p>
<p>If you use a class attribute, then any object of that class type
(including inherited classes) shares that data.</p>
<p>And, if you use an object attribute, then every object of that class
type will have its own version of that data.</p>
<p>How do you choose which one to use?  My ground rule is to minimize the
use of more widely shared data.  If it's possible to use an object
variable, do so; otherwise, use either a module or class attribute.
(In practice I almost never use class attributes, and infrequently use
module globals.)</p>
<!-- CTB consider examples: singleton; caching experience; ...? -->
</div>
<div class="section">
<h2><a class="toc-backref" href="#id19" id="how-modules-are-loaded-and-when-code-is-executed" name="how-modules-are-loaded-and-when-code-is-executed">How modules are loaded (and when code is executed)</a></h2>
<p>Something that has been implicit in the discussion of scope and data
sharing, above, is the order in which module code is executed.  There
shouldn't be any surprises here if you've been using Python for a
while, so I'll be brief: in general, the code at the top level of a
module is executed at <em>first</em> import, and all other code is executed
in the order you specify when you start calling functions or methods.</p>
<p>Note that because the top level of a module is executed precisely
once, at <em>first</em> import, the following code prints &quot;hello, world&quot; only
once:</p>
<pre class="literal-block">
mod_a.py:
  def f():
     print 'hello, world'

  f()

mod_b.py:
  import mod_a
</pre>
<p>The <tt class="docutils literal"><span class="pre">reload</span></tt> function will reload the module and force re-execution at
the top level:</p>
<pre class="literal-block">
reload(sys.modules['mod_a'])
</pre>
<p>It is also worth noting that the module name is bound to the local
namespace <em>prior</em> to the execution of the code in the module, so not
all symbols in the module are immediately available.  This really only
impacts you if you have interdependencies between modules: for
example, this will work if <tt class="docutils literal"><span class="pre">mod_a</span></tt> is imported before <tt class="docutils literal"><span class="pre">mod_b</span></tt>:</p>
<pre class="literal-block">
mod_a.py:
  import mod_b

mod_b.py:
  import mod_a
</pre>
<p>while this will not:</p>
<pre class="literal-block">
mod_a.py:
  import mod_b
  x = 5

mod_b.py:
  import mod_a
  y = mod_a.x
</pre>
<p>To see why, let's put in some print statements:</p>
<pre class="literal-block">
mod_a.py:
  print 'at top of mod_a'
  import mod_b
  print 'mod_a: defining x'
  x = 5

mod_b.py:
  print 'at top of mod_b'
  import mod_a
  print 'mod_b: defining y'
  y = mod_a.x
</pre>
<p>Now try <tt class="docutils literal"><span class="pre">import</span> <span class="pre">mod_a</span></tt> and <tt class="docutils literal"><span class="pre">import</span> <span class="pre">mod_b</span></tt>, each time in a new
interpreter:</p>
<pre class="literal-block">
&gt;&gt; import mod_a
at top of mod_a
at top of mod_b
mod_b: defining y
Traceback (most recent call last):
  File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;
  File &quot;mod_a.py&quot;, line 2, in &lt;module&gt;
    import mod_b
  File &quot;mod_b.py&quot;, line 4, in &lt;module&gt;
    y = mod_a.x
AttributeError: 'module' object has no attribute 'x'

&gt;&gt; import mod_b
at top of mod_b
at top of mod_a
mod_a: defining x
mod_b: defining y
</pre>
</div>
<div class="section">
<h2><a class="toc-backref" href="#id20" id="pythonpath-and-finding-packages-modules-during-development" name="pythonpath-and-finding-packages-modules-during-development">PYTHONPATH, and finding packages &amp; modules during development</a></h2>
<p>So, you've got your re-usable code nicely defined in modules, and now you
want to ... use it.  How can you import code from multiple locations?</p>
<p>The simplest way is to set the PYTHONPATH environment variable to
contain a list of directories from which you want to import code;
e.g. in UNIX bash,</p>
<pre class="literal-block">
% export PYTHONPATH=/path/to/directory/one:/path/to/directory/two
</pre>
<p>or in csh,</p>
<pre class="literal-block">
% setenv PYTHONPATH /path/to/directory/one:/path/to/directory/two
</pre>
<p>Under Windows,</p>
<pre class="literal-block">
&gt; set PYTHONPATH directory1;directory2
</pre>
<p>should work.</p>
<!-- @CTB test -->
<p>However, setting the PYTHONPATH explicitly can make your code less
movable in practice, because you will forget (and fail to document)
the modules and packages that your code depends on.  I prefer to modify
sys.path directly:</p>
<pre class="literal-block">
import sys
sys.path.insert(0, '/path/to/directory/one')
sys.path.insert(0, '/path/to/directory/two')
</pre>
<p>which has the advantage that you are explicitly specifying the location
of packages that you depend upon in the dependent code.</p>
<p>Note also that you can put modules and packages in zip files and
Python will be able to import directly from the zip file; just place
the path to the zip file in either <tt class="docutils literal"><span class="pre">sys.path</span></tt> or your PYTHONPATH.</p>
<p>Now, I tend to organize my projects into several directories, with a
<tt class="docutils literal"><span class="pre">bin/</span></tt> directory that contains my scripts, and a <tt class="docutils literal"><span class="pre">lib/</span></tt> directory
that contains modules and packages.  If I want to to deploy this code
in multiple locations, I can't rely on inserting absolute paths into
sys.path; instead, I want to use relative paths.  Here's the trick I use</p>
<p>In my script directory, I write a file <tt class="docutils literal"><span class="pre">_mypath.py</span></tt>.</p>
<pre class="literal-block">
_mypath.py:
   import os, sys
   thisdir = os.path.dirname(__file__)
   libdir = os.path.join(thisdir, '../relative/path/to/lib/from/bin')

   if libdir not in sys.path:
      sys.path.insert(0, libdir)
</pre>
<p>Now, in each script I put <tt class="docutils literal"><span class="pre">import</span> <span class="pre">_mypath</span></tt> at the top of the script.
When running scripts, Python automatically enters the script's
directory into sys.path, so the script can import _mypath.  Then
_mypath uses the special attribute __file__ to calculate its own
location, from which it can calculate the absolute path to the library
directory and insert the library directory into <tt class="docutils literal"><span class="pre">sys.path</span></tt>.</p>
</div>
<div class="section">
<h2><a class="toc-backref" href="#id21" id="setup-py-and-distutils-the-old-fashioned-way-of-installing-python-packages" name="setup-py-and-distutils-the-old-fashioned-way-of-installing-python-packages">setup.py and distutils: the old fashioned way of installing Python packages</a></h2>
<p>While developing code, it's easy to simply work out of the development
directory.  However, if you want to pass the code onto others as a
finished module, or provide it to systems admins, you might want to
consider writing a <tt class="docutils literal"><span class="pre">setup.py</span></tt> file that can be used to install your
code in a more standard way.  setup.py lets you use <a class="reference" href="http://docs.python.org/dist/dist.html">distutils</a> to install the software by
running</p>
<pre class="literal-block">
python setup.py install
</pre>
<p>Writing a setup.py is simple, especially if your package is pure Python
and doesn't include any extension files.  A setup.py file for a pure Python
install looks like this:</p>
<pre class="literal-block">
from distutils.core import setup
setup(name='your_package_name',
      py_modules = ['module1', 'module2']
      packages = ['package1', 'package2']
      scripts = ['script1', 'script2'])
</pre>
<p>One this script is written, just drop it into the top-level directory
and type <tt class="docutils literal"><span class="pre">python</span> <span class="pre">setup.py</span> <span class="pre">build</span></tt>.  This will make sure that distutils
can find all the files.</p>
<p>Once your setup.py works for building, you can package up the entire
directory with tar or zip and anyone should be able to install it by
unpacking the package and typing</p>
<pre class="literal-block">
% python setup.py install
</pre>
<p>This will copy the packages and modules into Python's
<tt class="docutils literal"><span class="pre">site-packages</span></tt> directory, and install the scripts into Python's
script directory.</p>
</div>
<div class="section">
<h2><a class="toc-backref" href="#id22" id="setup-py-eggs-and-easy-install-the-new-fangled-way-of-installing-python-packages" name="setup-py-eggs-and-easy-install-the-new-fangled-way-of-installing-python-packages">setup.py, eggs, and easy_install: the new fangled way of installing Python packages</a></h2>
<p>A somewhat newer (and better) way of distributing Python software is
to use easy_install, a system developed by Phillip Eby as part of the
setuptools package.  Many of the capabilities of
easy_install/setuptools are probably unnecessary for scientific Python
developers (although it's an excellent way to install Python packages
from other sources), so I will focus on three capabilities that I
think are most useful for &quot;in-house&quot; development: versioning, user
installs, and binary eggs.</p>
<p>First, install easy_install/setuptools.  You can do this by downloading</p>
<pre class="literal-block">
http://peak.telecommunity.com/dist/ez_setup.py
</pre>
<p>and running <tt class="docutils literal"><span class="pre">python</span> <span class="pre">ez_setup.py</span></tt>.  (If you can't do this as the
superuser, see the note below about user installs.)  Once you've
installed setuptools, you should be able to run the script
<tt class="docutils literal"><span class="pre">easy_install</span></tt>.</p>
<p>The first thing this lets you do is easily install any software that
is distutils-compatible.  You can do this from a number of sources:
from an unpackaged directory (as with <tt class="docutils literal"><span class="pre">python</span> <span class="pre">setup.py</span> <span class="pre">install</span></tt>);
from a tar or zip file; from the project's URL or Web page; from an
egg (see below); or from PyPI, the Python Package Index (see
<a class="reference" href="http://cheeseshop.python.org/pypi/">http://cheeseshop.python.org/pypi/</a>).</p>
<p>Let's try installing <tt class="docutils literal"><span class="pre">nose</span></tt>, a unit test discovery package we'll be
looking at in the testing section (below).  Type:</p>
<pre class="literal-block">
easy_install --install-dir=~/.packages nose
</pre>
<p>This will go to the Python Package Index, find the URL for nose,
download it, and install it in your ~/.packages directory.  We're
specifying an install-dir so that you can install it for your use
only; if you were the superuser, you could install it for everyone by
omitting '--install-dir'.</p>
<p>(Note that you need to add ~/.packages to your PATH and your
PYTHONPATH, something I've already done for you.)</p>
<p>So, now, you can go do 'import nose' and it will work.  Neat, eh?
Moreover, the nose-related scripts (<tt class="docutils literal"><span class="pre">nosetests</span></tt>, in this case) have
been installed for your use as well.</p>
<p>You can also install specific versions of software; right now, the
latest version of nose is 0.9.3, but if you wanted 0.9.2, you could
specify <tt class="docutils literal"><span class="pre">easy_install</span> <span class="pre">nose==0.9.2</span></tt> and it would do its best to find
it.</p>
<p>This leads to the next setuptools feature of note,
<tt class="docutils literal"><span class="pre">pkg_resource.require</span></tt>.  <tt class="docutils literal"><span class="pre">pkg_resources.require</span></tt> lets you specify
that certain packages must be installed.  Let's try it out by
requiring that CherryPy 3.0 or later is installed:</p>
<pre class="literal-block">
&gt;&gt; import pkg_resources
&gt;&gt; pkg_resources.require('CherryPy &gt;= 3.0')
Traceback (most recent call last):
     ...
DistributionNotFound: CherryPy &gt;= 3.0
</pre>
<p>OK, so that failed... but now let's install CherryPy:</p>
<pre class="literal-block">
% easy_install --install-dir=~/.packages CherryPy
</pre>
<p>Now the require will work:</p>
<pre class="literal-block">
&gt;&gt; pkg_resources.require('CherryPy &gt;= 3.0')
&gt;&gt; import CherryPy
</pre>
<p>This version requirement capability is quite powerful, because it lets
you specify exactly the versions of the software you need for your own
code to work.  And, if you need multiple versions of something
installed, setuptools lets you do that, too -- see the
<tt class="docutils literal"><span class="pre">--multi-version</span></tt> flag for more information.  While you still can't
use <em>different</em> versions of the same package in the same program, at
least you can have multiple versions of the same package installed!</p>
<p>Throughout this, we've been using another great feature of setuptools:
user installs.  By specifying the <tt class="docutils literal"><span class="pre">--install-dir</span></tt>, you can install
most Python packages for yourself, which lets you take advantage of
easy_install's capabilities without being the superuser on your
development machine.</p>
<p>This brings us to the last feature of setuptools that I want to
mention: eggs, and in particular binary eggs.  We'll explore binary
eggs later; for now let me just say that easy_install makes it
possible for you to package up multiple binary versions of your
software (<em>with</em> extension modules) so that people don't have to
compile it themselves.  This is an invaluable and somewhat
underutilized feature of easy_install, but it can make life much
easier for your users.</p>
</div>
</div>
<div class="section">
<h1><a class="toc-backref" href="#id23" id="testing-your-software" name="testing-your-software">Testing Your Software</a></h1>
<p>&quot;Debugging is twice as hard as writing the code in the first place.
Therefore, if you write the code as cleverly as possible, you are, by
definition, not smart enough to debug it.&quot;  -- Brian W. Kernighan.</p>
<p>Everyone tests their software to some extent, if only by running it
and trying it out (technically known as &quot;smoke testing&quot;).  Most
programmers do a certain amount of exploratory testing, which involves
running through various functional paths in your code and seeing if
they work.</p>
<p>Systematic testing, however, is a different matter.  Systematic
testing simply cannot be done properly without a certain (large!)
amount of automation, because every change to the software means that
the software needs to be tested all over again.</p>
<p>Below, I will introduce you to some lower level automated testing
concepts, and show you how to use built-in Python constructs to start
writing tests.</p>
<div class="section">
<h2><a class="toc-backref" href="#id24" id="an-introduction-to-testing-concepts" name="an-introduction-to-testing-concepts">An introduction to testing concepts</a></h2>
<p>There are several types of tests that are particularly useful to
research programmers.  <em>Unit tests</em> are tests for fairly small and
specific units of functionality.  <em>Functional tests</em> test entire
functional paths through your code.  <em>Regression tests</em> make sure
that (within the resolution of your records) your program's output
has not changed.</p>
<p>All three types of tests are necessary in different ways.</p>
<p>Regression tests tell you when unexpected changes in behavior occur,
and can reassure you that your basic data processing is still working.
For scientists, this is particularly important if you are trying to
link past research results to new research results: if you can no
longer replicate your original results with your updated code, then
you must regard your code with suspicion, <em>unless</em> the changes are
intentional.</p>
<p>By contrast, both unit and functional tests tend to be <em>expectation</em>
based.  By this I mean that you use the tests to lay out what behavior
you <em>expect</em> from your code, and write your tests so that they <em>assert</em>
that those expectations are met.</p>
<p>The difference between unit and functional tests is blurry in most
actual implementations; unit tests tend to be much shorter and require
less setup and teardown, while functional tests can be quite long. I
like Kumar McMillan's distinction: functional tests tell you <em>when</em>
your code is broken, while unit tests tell you <em>where</em> your code is
broken.  That is, because of the finer granularity of unit tests, a
broken unit test can identify a particular piece of code as the source
of an error, while functional tests merely tell you that a feature is
broken.</p>
</div>
<div class="section">
<h2><a class="toc-backref" href="#id25" id="the-doctest-module" name="the-doctest-module">The doctest module</a></h2>
<p>Let's start by looking at the doctest module.  If you've been
following along, you will be familiar with doctests, because I've been
using them throughout this text!  A doctest links code and behavior
explicitly in a nice documentation format.  Here's an example:</p>
<pre class="doctest-block">
&gt;&gt;&gt; print 'hello, world'
hello, world
</pre>
<p>When doctest sees this in a docstring or in a file, it knows that it
should execute the code after the '&gt;&gt;&gt;' and compare the actual output
of the code to the strings immediately following the '&gt;&gt;&gt;' line.</p>
<p>To execute doctests, you can use the doctest API that comes with
Python: just type:</p>
<pre class="literal-block">
import doctest
doctest.testfile(textfile)
</pre>
<p>or</p>
<pre class="literal-block">
import doctest
doctest.testmod(modulefile)
</pre>
<p>The doctest docs contain complete documentation for the module, but
in general there are only a few things you need to know.</p>
<p>First, for multi-line entries, use '...' instead of '&gt;&gt;&gt;':</p>
<pre class="doctest-block">
&gt;&gt;&gt; def func():
...   print 'hello, world'
&gt;&gt;&gt; func()
hello, world
</pre>
<p>Second, if you need to elide exception code, use '...':</p>
<pre class="doctest-block">
&gt;&gt;&gt; raise Exception(&quot;some error occurred&quot;)
Traceback (most recent call last):
   ...
Exception: some error occurred
</pre>
<p>More generally, you can use '...' to match random output, as long as you
you specify a doctest directive:</p>
<pre class="doctest-block">
&gt;&gt;&gt; import random
&gt;&gt;&gt; print 'random number:', random.randint(0, 10)  # doctest: +ELLIPSIS
random number: ...
</pre>
<p>Third, doctests are terminated with a blank line, so if you
explicitly expect a blank line, you need to use a special construct:</p>
<pre class="doctest-block">
&gt;&gt;&gt; print ''
&lt;BLANKLINE&gt;
</pre>
<p>To test out some doctests of your own, try modifying these files
and running them with <tt class="docutils literal"><span class="pre">doctest.testfile</span></tt>.</p>
<p>Doctests are useful in a number of ways.  They encourage a kind of
conversation with the user, in which you (the author) demonstrate how
to actually use the code.  And, because they're executable, they
ensure that your code works as you expect.  However, they can also
result in quite long docstrings, so I recommend putting long doctests
in files separate from the code files.  Short doctests can go anywhere
-- in module, class, or function docstrings.</p>
</div>
<div class="section">
<h2><a class="toc-backref" href="#id26" id="unit-tests-with-unittest" name="unit-tests-with-unittest">Unit tests with unittest</a></h2>
<p>If you've heard of automated testing, you've almost certainly heard of
unit tests.  The idea behind unit tests is that you can constrain the
behavior of small units of code to be correct by testing the bejeezus
out of them; and, if your smallest code units are broken, then how can
code built on top of them be good?</p>
<p>The <a class="reference" href="http://docs.python.org/lib/module-unittest.html">unittest module</a>
comes with Python.  It provides a framework for writing and running
unit tests that is at least convenient, if not as simple as it could be
(see the 'nose' stuff, below, for something that is simpler).</p>
<p>Unit tests are almost always demonstrated with some sort of numerical
process, and I will be no different.  Here's a simple unit test, using
the unittest module:</p>
<pre class="literal-block">
test_sort.py:

 #! /usr/bin/env python
 import unittest
 class Test(unittest.TestCase):
  def test_me(self):
     seq = [ 5, 4, 1, 3, 2 ]
     seq.sort()
     self.assertEqual(seq, [1, 2, 3, 4, 5])

 if __name__ == '__main__':
    unittest.main()
</pre>
<p>If you run this, you'll see the following output:</p>
<pre class="literal-block">
.
----------------------------------------------------------------------
Ran 1 test in 0.000s

OK
</pre>
<p>Here, <tt class="docutils literal"><span class="pre">unittest.main()</span></tt> is running through all of the symbols in the
global module namespace and finding out which classes inherit from
<tt class="docutils literal"><span class="pre">unittest.TestCase</span></tt>.  Then, for each such class, it finds all methods
starting with <tt class="docutils literal"><span class="pre">test</span></tt>, and for each one it instantiates a new object
and runs the function: so, in this case, just:</p>
<pre class="literal-block">
Test().test_me()
</pre>
<p>If any method fails, then the failure output is recorded and presented
at the end, but the rest of the test methods are run irrespective.</p>
<p><tt class="docutils literal"><span class="pre">unittest</span></tt> also includes support for test <em>fixtures</em>, which are functions
run before and after each test; the idea is to use them to set up and
tear down the test environment.  In the code below, <tt class="docutils literal"><span class="pre">setUp</span></tt> creates
and shuffles the <tt class="docutils literal"><span class="pre">self.seq</span></tt> sequence, while <tt class="docutils literal"><span class="pre">tearDown</span></tt> deletes it.</p>
<pre class="literal-block">
test_sort2.py:

   #! /usr/bin/env python
   import unittest
   import random

   class Test(unittest.TestCase):
       def setUp(self):
           self.seq = range(0, 10)
           random.shuffle(self.seq)

       def tearDown(self):
           del self.seq

       def test_basic_sort(self):
           self.seq.sort()
           self.assertEqual(self.seq, range(0, 10))

       def test_reverse(self):
           self.seq.sort()
           self.seq.reverse()
           self.assertEqual(self.seq, [9, 8, 7, 6, 5, 4, 3, 2, 1, 0])

       def test_destruct(self):
           self.seq.sort()
           del self.seq[-1]
           self.assertEqual(self.seq, range(0, 9))

   unittest.main()
</pre>
<p>In both of these examples, it's important to realize that an <em>entirely
new object</em> is created, and the fixtures run, for each test function.  This
lets you write tests that alter or destroy test data without having to
worry about interactions between the code in different tests.</p>
</div>
<div class="section">
<h2><a class="toc-backref" href="#id27" id="testing-with-nose" name="testing-with-nose">Testing with nose</a></h2>
<p>nose is a unit test discovery system that makes writing and organizing
unit tests very easy.  I've actually written a whole separate article on
them, so we should go <a class="reference" href="nose-intro.html">check that out</a>.</p>
<!-- (CTB: testing primes?) -->
</div>
<div class="section">
<h2><a class="toc-backref" href="#id28" id="code-coverage-analysis" name="code-coverage-analysis">Code coverage analysis</a></h2>
<p><a class="reference" href="http://darcs.idyll.org/~t/projects/figleaf/README.html">figleaf</a>
is a code coverage recording and analysis system that I wrote and
maintain.  It's published in PyPI, so you can install it with
easy_install.</p>
<p>Basic use of figleaf is very easy.  If you have a script <tt class="docutils literal"><span class="pre">program.py</span></tt>,
rather than typing</p>
<pre class="literal-block">
% python program.py
</pre>
<p>to run the script, run</p>
<pre class="literal-block">
% figleaf program.py
</pre>
<p>This will transparently and invisibly record coverage to the file
'.figleaf' in the current directory.  If you run the program several
times, the coverage will be aggregated.</p>
<p>To get a coverage report, run 'figleaf2html'.  This will produce a
subdirectory <tt class="docutils literal"><span class="pre">html/</span></tt> that you can view with any Web browser; the
index.html file will contain a summary of the code coverage, along
with links to individual annotated files.  In these annotated files,
executed lines are colored green, while lines of code that are not
executed are colored red.  Lines that are not considered lines of code
(e.g. docstrings, or comments) are colored black.</p>
<p>My main use for code coverage analysis is in testing (which is why I
discuss it in this section!)  I record the code coverage for my unit
and functional tests, and then examine the output to figure out which
files or libraries to focus on testing next.  As I discuss below, it
is relatively easy to achieve 70-80% code coverage by this method.</p>
<p>When is code coverage most useful?  I think it's most useful in the
early and middle stages of testing, when you need to track down code
that is not touched by your tests.  However, 100% code coverage by your
tests doesn't guarantee bug free code: this is because figleaf only measures
line coverage, not branch coverage.  For example, consider this code:</p>
<pre class="literal-block">
if a.x or a.y:
   f()
</pre>
<p>If <tt class="docutils literal"><span class="pre">a.x</span></tt> is True in all your tests, then <tt class="docutils literal"><span class="pre">a.y</span></tt> will never be
evaluated -- even though <tt class="docutils literal"><span class="pre">a</span></tt> may not have an attribute <tt class="docutils literal"><span class="pre">y</span></tt>, which
would cause an AttributeError (which would in turn be a bug, if not
properly caught).  Python does not record which subclauses of the
<tt class="docutils literal"><span class="pre">if</span></tt> statement are executed, so without analyzing the structure of
the program there's no simple way to figure it out.</p>
<p>Here's another buggy example with 100% code coverage:</p>
<pre class="literal-block">
def f(a):
   if a:
      a = a.upper()
   return a.strip()

s = f(&quot;some string&quot;)
</pre>
<p>Here, there's an implicit <tt class="docutils literal"><span class="pre">else</span></tt> after the if statement; the function f()
could be rewritten to this:</p>
<pre class="literal-block">
def f(a):
   if a:
      a = a.upper()
   else:
      pass
   return a.strip()

s = f(&quot;some string&quot;)
</pre>
<p>and the pass statement would show up as &quot;not executed&quot;.</p>
<p>So, bottom line: 100% test coverage is <em>necessary</em> for a well-tested
program, because code that is not executed by any test at all is
simply not being tested.  However, 100% test coverage is not
<em>sufficient</em> to guarantee that your program is free of bugs, as you can
see from some of the examples above.</p>
</div>
<div class="section">
<h2><a class="toc-backref" href="#id29" id="adding-tests-to-an-existing-project" name="adding-tests-to-an-existing-project">Adding tests to an existing project</a></h2>
<p>This testing discussion should help to convince you that not only
<em>should</em> you test, but that there are plenty of tools available to
<em>help</em> you test in Python.  It may even give you some ideas about how
to start testing new projects.  However, retrofitting an <em>existing</em>
project with tests is a different, challenging problem -- where do you
start?  People are often overwhelmed by the amount of code they've
written in the past.</p>
<p>I suggest the following approach.</p>
<p>First, start by writing a test for each bug as they are discovered.
The procedure is fairly simple: isolate the cause of the bug; write a
test that demonstrates the bug; fix the bug; verify that the test
passes.  This has several benefits in the short term: you are fixing
bugs, you're discovering weak points in your software, you're becoming
more familiar with the testing approach, and you can start to think
about commonalities in the fixtures necessary to <em>support</em> the tests.</p>
<p>Next, take out some time -- half a day or so -- and write fixtures and
functional tests for some small chunk of code; if you can, pick a piece
of code that you're planning to clean up or extend.  Don't worry about
being exhaustive, but just write tests that target the main point of
the code that you're working on.</p>
<p>Repeat this a few times.  You should start to discover the benefits of
testing at this point, as you increasingly prevent bugs from occurring
in the code that's covered by the tests.  You should also start to get
some idea of what fixtures are necessary for your code base.</p>
<p>Now use code coverage analysis to analyze what code your tests cover,
and what code isn't covered.  At this point you can take a targetted
approach and spend some time writing tests aimed directly at uncovered
areas of code.  There should now be tests that cover 30-50% of your
code, at least (it's very easy to attain this level of code
coverage!).</p>
<p>Once you've reached this point, you can either decide to focus on
increasing your code coverage, or (my recommendation) you can simply
continue incrementally constraining your code by writing tests for bugs
and new features.  Assuming you have a fairly normal code churn, you should
get to the point of 70-80% coverage within a few months to a few years
(depending on the size of the project!)</p>
<p>This approach is effective because at each stage you get immediate
feedback from your efforts, and it's easier to justify to managers
than a whole-team effort to add testing.  Plus, if you're unfamiliar
with testing or with parts of the code base, it gives you time to adjust
and adapt your approach to the needs of the particular project.</p>
<p>Two articles that discuss similar approaches in some detail are
available online: <a class="reference" href="http://www.stickyminds.com/s.asp?F=S9705_MAGAZINE_2">Strangling Legacy Code</a>, and <a class="reference" href="http://www.developertesting.com/archives/GrowYourHarness.pdf">Growing
Your Test Harness</a>.  I
can also recommend the book <a class="reference" href="http://www.amazon.com/Working-Effectively-Legacy-Robert-Martin/dp/0131177052">Working Effectively with Legacy Code</a>,
by Robert Martin.</p>
</div>
<div class="section">
<h2><a class="toc-backref" href="#id30" id="concluding-thoughts-on-automated-testing" name="concluding-thoughts-on-automated-testing">Concluding thoughts on automated testing</a></h2>
<p>Starting to do automated testing of your code can lead to immense
savings in maintenance and can also increase productivity
dramatically.  There are a number of reasons why automated testing can
help so much, including quick discovery of regressions, increased
design awareness due to more interaction with the code, and early
detection of simple bugs as well as unwanted epistatic interactions
between code modules.  The single biggest improvement for me has been
the ability to refactor code without worrying as much about breakage.
In my personal experience, automated testing is a 5-10x productivity
booster when working alone, and it can save multi-person teams from
potentially disastrous errors in communication.</p>
<p>Automated testing is not, of course, a silver bullet.  There are several
common worries.</p>
<p>One worry is that by increasing the total amount of code in a project,
you increase both the development time and the potential for bugs and
maintenance problems.  This is certainly possible, but test code is
very different from regular project code: it can be removed much more
easily (which can be done whenever the code being tested undergoes
revision), and it should be <em>much</em> simpler even if it is in fact
bulkier.</p>
<p>Another worry is that too much of a focus on testing will decrease the
drive for new functionality, because people will focus more on writing
tests than they will on the new code.  While this is partly a
managerial issues, it is worth pointing out that the process of
writing new code will be dramatically faster if you don't have to
worry about old code breaking in unexpected ways as you add
functionality.</p>
<p>A third worry is that by focusing on automation, you will miss bugs in
code that is difficult to automate.  There are two considerations
here.  First, it is possible to automate quite a bit of testing; the
decision not to automat a particular test is almost always made
because of financial or time considerations rather than technical
limitations.  And, second, automated testing is simply not a
replacement for certain types of manual testing -- in particular,
exploratory testing, in which the programmers or users interact with
the program, will always turn up new bugs, and is worth doing
independent of the automated tests.</p>
<p>How much to test, and what to test, are decisions that need to be made
on an individual project basis; there are no hard and fast rules.
However, I feel confident in saying that some automated testing will
always improve the quality of your code and result in maintenance
improvements.</p>
</div>
</div>
<div class="section">
<h1><a class="toc-backref" href="#id31" id="an-extended-introduction-to-the-nose-unit-testing-framework" name="an-extended-introduction-to-the-nose-unit-testing-framework">An Extended Introduction to the nose Unit Testing Framework</a></h1>
<p>Welcome! This is an introduction, with lots and lots of examples, to the
<a class="reference" href="http://somethingaboutorange.com/mrl/projects/nose/">nose</a> unit test discovery &amp; execution framework.  If that's not what
you want to read, I suggest you hit the Back button now.</p>
<p>The latest version of this document can be found at</p>
<blockquote>
<a class="reference" href="http://ivory.idyll.org/articles/nose-intro.html">http://ivory.idyll.org/articles/nose-intro.html</a></blockquote>
<p>(Last modified October 2006.)</p>
<div class="section">
<h2><a class="toc-backref" href="#id32" id="what-are-unit-tests" name="what-are-unit-tests">What are unit tests?</a></h2>
<p>A unit test is an automated code-level test for a small &quot;unit&quot; of
functionality.  Unit tests are often designed to test a broad range of the
expected functionality, including any weird corner cases and some
tests that <em>should not</em> work.  They tend to interact minimally with
external resources like the disk, the network, and databases; testing
code that accesses these resources is usually put under functional
tests, regression tests, or integration tests.</p>
<p>(There's lots of discussion on whether unit tests should do things
like access external resources, and whether or not they are still
&quot;unit&quot; tests if they do.  The arguments are fun to read, and I
encourage you to read them.  I'm going to stick with a fairly
pragmatic and broad definition: anything that exercises a small, fairly
isolated piece of functionality is a unit test.)</p>
<p>Unit tests are almost always pretty simple, by intent; for example, if
you wanted to test an (intentionally naive) regular expression for
validating the form of e-mail addresses, your test might look something
like this:</p>
<pre class="literal-block">
EMAIL_REGEXP = r'[\S.]+&#64;[\S.]+'

def test_email_regexp():
   # a regular e-mail address should match
   assert re.match(EMAIL_REGEXP, 'test&#64;nowhere.com')

   # no domain should fail
   assert not re.match(EMAIL_REGEXP, 'test&#64;')
</pre>
<p>There are a couple of ways to integrate unit tests into your
development style. These include Test Driven Development, where unit
tests are written prior to the functionality they're testing; during
refactoring, where existing code -- sometimes code without any
automated tests to start with -- is retrofitted with unit tests as
part of the refactoring process; bug fix testing, where bugs are first
pinpointed by a targetted test and then fixed; and straight test
enhanced development, where tests are written organically as the code
evolves.  In the end, I think it matters more that you're writing unit
tests than it does exactly how you write them.</p>
<p>For me, the most important part of having unit tests is that they can
be run <em>quickly</em>, <em>easily</em>, and <em>without any thought</em> by developers.
They serve as executable, enforceable documentation for function and
API, and they also serve as an invaluable reminder of bugs you've
fixed in the past.  As such, they improve my ability to more quickly
deliver functional code -- and that's really the bottom line.</p>
</div>
<div class="section">
<h2><a class="toc-backref" href="#id33" id="why-use-a-framework-and-why-nose" name="why-use-a-framework-and-why-nose">Why use a framework? (and why nose?)</a></h2>
<p>It's pretty common to write tests for a library module like so:</p>
<pre class="literal-block">
def test_me():
   # ... many tests, which raise an Exception if they fail ...

if __name__ -- '__main__':
   test_me()
</pre>
<p>The 'if' statement is a little hook that runs the tests when the module
is executed as a script from the command line.  This is great, and fulfills
the goal of having automated tests that can be run easily.  Unfortunately,
they <em>cannot be run without thought</em>, which is an amazingly important and
oft-overlooked requirement for automated tests!  In practice, this means
that they will only be run when that module is being worked on -- a big
problem.</p>
<p>People use unit test discovery and execution frameworks so that they
can add tests to existing code, execute those tests, and get a simple
report, without thinking.  Below, you'll see some of the advantages
that using such a framework gives you: in addition to finding and
running your tests, frameworks can let you selectively execute
certain tests, capture and collate error output, and add coverage and
profiling information.  (You can always write your own framework --
but why not take advantage of someone else's, even if they're not as
smart as you?)</p>
<p>&quot;Why use nose in particular?&quot; is a more difficult question.  There are
many unit test frameworks in Python, and more arise every day.  I
personally use nose, and it fits my needs fairly well.  In particular,
it's actively developed, by a guy (Jason Pellerin) who answers his
e-mail pretty quickly; it's fairly stable (it's in beta at the time of
this writing); it has a really fantastic plug-in architecture that lets
me extend it in convenient ways; it integrates well with distutils;
it can be adapted to mimic any <em>other</em> unit test discovery framework
pretty easily; and it's being used by a number of big projects, which
means it'll probably still be around in a few years.</p>
<p>I hope the best reason <em>for you</em> to use nose will be that I'm giving
you this extended introduction ;).</p>
</div>
<div class="section">
<h2><a class="toc-backref" href="#id34" id="a-few-simple-examples" name="a-few-simple-examples">A few simple examples</a></h2>
<p>First, install nose.  Using <a class="reference" href="http://peak.telecommunity.com/DevCenter/setuptools">setuptools</a>, this is easy:</p>
<pre class="literal-block">
easy_install nose
</pre>
<p>Now let's start with a few examples.  Here's the simplest nose test you
can write:</p>
<pre class="literal-block">
def test_b():
    assert 'b' -- 'b'
</pre>
<p>Put this in a file called <tt class="docutils literal"><span class="pre">test_me.py</span></tt>, and then run <tt class="docutils literal"><span class="pre">nosetests</span></tt>.
You will see this output:</p>
<pre class="literal-block">
.
----------------------------------------------------------------------
Ran 1 test in 0.005s

OK
</pre>
<p>If you want to see exactly what test was run, you can use <tt class="docutils literal"><span class="pre">nosetests</span> <span class="pre">-v</span></tt>.</p>
<pre class="literal-block">
test_stuff.test_b ... ok

----------------------------------------------------------------------
Ran 1 test in 0.015s

OK
</pre>
<p>Here's a more complicated example.</p>
<pre class="literal-block">
class TestExampleTwo:
    def test_c(self):
        assert 'c' -- 'c'
</pre>
<p>Here, nose will first create an object of type <tt class="docutils literal"><span class="pre">TestExampleTwo</span></tt>, and
only <em>then</em> run <tt class="docutils literal"><span class="pre">test_c</span></tt>:</p>
<pre class="literal-block">
test_stuff.TestExampleTwo.test_c ... ok
</pre>
<p>Most new test functions you write should look like either of these tests --
a simple test function, or a class containing one or more test functions.
But don't worry -- if you have some old tests that you ran with <tt class="docutils literal"><span class="pre">unittest</span></tt>,
you can still run them.  For example, this test:</p>
<pre class="literal-block">
class ExampleTest(unittest.TestCase):
    def test_a(self):
        self.assert_(1 -- 1)
</pre>
<p>still works just fine:</p>
<pre class="literal-block">
test_a (test_stuff.ExampleTest) ... ok
</pre>
<div class="section">
<h3><a class="toc-backref" href="#id35" id="test-fixtures" name="test-fixtures">Test fixtures</a></h3>
<p>A fairly common pattern for unit tests is something like this:</p>
<pre class="literal-block">
def test():
   setup_test()
   try:
      do_test()
      make_test_assertions()
   finally:
      cleanup_after_test()
</pre>
<p>Here, <tt class="docutils literal"><span class="pre">setup_test</span></tt> is a function that creates necessary objects,
opens database connections, finds files, etc. -- anything that
establishes necessary preconditions for the test.  Then <tt class="docutils literal"><span class="pre">do_test</span></tt>
and <tt class="docutils literal"><span class="pre">make_test_assertions</span></tt> acually run the test code and check to
see that the test completed successfully.  Finally -- and independently
of whether or not the test <em>succeeded</em> -- the preconditions are cleaned
up, or &quot;torn down&quot;.</p>
<p>This is such a common pattern for unit tests that most unit test frameworks
let you define setup and teardown &quot;fixtures&quot; for each test; these fixtures
are run before and after the test, as in the code sample above.  So, instead
of the pattern above, you'd do:</p>
<pre class="literal-block">
def test():
   do_test()
   make_test_assertions()

test.setUp = setup_test
test.tearDown = cleanup_after_test
</pre>
<p>The unit test framework then examines each test function, class, and
method for fixtures, and runs them appropriately.</p>
<p>Here's the canonical example of fixtures, used in classes rather than in
functions:</p>
<pre class="literal-block">
class TestClass:
   def setUp(self):
      ...

   def tearDown(self):
      ...

   def test_case_1(self):
      ...

   def test_case_2(self):
      ...

   def test_case_3(self):
      ...
</pre>
<p>The code that's actually run by the unit test framework is then</p>
<pre class="literal-block">
for test_method in get_test_classes():
   obj = TestClass()
   obj.setUp()
   try:
      obj.test_method()
   finally:
      obj.tearDown()
</pre>
<p>That is, for <em>each</em> test case, a new object is created, set up, and torn
down -- thus approximating the Platonic ideal of running each test in a
completely new, pristine environment.</p>
<p>(Fixture, incidentally, comes from the Latin &quot;fixus&quot;, meaning &quot;fixed&quot;.
The origin of its use in unit testing is not clear to me, but you can
think of fixtures as permanent appendages of a set of tests, &quot;fixed&quot;
in place.  The word &quot;fixtures&quot; make more sense when considered as part of a
test suite than when used on a single test -- one fixture for each <em>set</em> of
tests.)</p>
</div>
<div class="section">
<h3><a class="toc-backref" href="#id36" id="examples-are-included" name="examples-are-included">Examples are included!</a></h3>
<p>All of the example code in this article is available in a .tar.gz file.
Just download the package at</p>
<pre class="literal-block">
http://darcs.idyll.org/~t/projects/nose-demo.tar.gz
</pre>
<p>and unpack it somewhere; information on running the examples is in
each section, below.</p>
<p>To run the simple examples above, go to the top directory in the
example distribution and type</p>
<pre class="literal-block">
nosetests -w simple/ -v
</pre>
</div>
</div>
<div class="section">
<h2><a class="toc-backref" href="#id37" id="a-somewhat-more-complete-guide-to-test-discovery-and-execution" name="a-somewhat-more-complete-guide-to-test-discovery-and-execution">A somewhat more complete guide to test discovery and execution</a></h2>
<p>nose is a unit test <strong>discovery</strong> and execution package.  Before it
can execute any tests, it needs to discover them.  nose has a set of
rules for discovering tests, and then a fixed protocol for running
them.  While both can be modified by plugins, for the moment let's
consider only the default rules.</p>
<p>nose only looks for tests under the working directory -- normally the
current directory, unless you specify one with the <tt class="docutils literal"><span class="pre">-w</span></tt> command line
option.</p>
<p>Within the working directory, it looks for any directories, files,
modules, or packages that match the test pattern. [ ... ]  In particular,
note that packages are recursively scanned for test cases.</p>
<p>Once a test module or a package is found, it's loaded, the setup
fixtures are run, and the modules are examined for test functions and
classes -- again, anything that matches the test pattern.  Any test
functions are run -- along with associated fixtures -- and test
classes are also executed.  For each test method in test classes, a
new object of that type is instantiated, the setup fixture (if any) is
run, the test method is run, and (if there was a setup fixture) the
teardown fixture is run.</p>
<div class="section">
<h3><a class="toc-backref" href="#id38" id="running-tests" name="running-tests">Running tests</a></h3>
<p>Here's the basic logic of test running used by nose (in Python pseudocode)</p>
<pre class="literal-block">
if has_setup_fixture(test):
   run_setup(test)

try:

   run_test(test)

finally:
   if has_setup_fixture(test):
      run_teardown(test)
</pre>
<p>Unlike tests themselves, however, test fixtures on test modules and
test packages are run only once.  This extends the test logic above to
this (again, pseudocode):</p>
<pre class="literal-block">
### run module setup fixture

if has_setup_fixture(test_module):
   run_setup(test_module)

### run all tests

try:
   for test in get_tests(test_module):

      try:                               ### allow individual tests to fail
         if has_setup_fixture(test):
            run_setup(test)

         try:

            run_test(test)

         finally:
            if has_setup_fixture(test):
               run_teardown(test)
      except:
         report_error()

finally:

   ### run module teardown fixture

   if has_setup_fixture(test_module):
      run_teardown(test_module)
</pre>
<p>A few additional notes:</p>
<blockquote>
<ul class="simple">
<li>if the setup fixture fails, no tests are run and the teardown fixture
isn't run, either.</li>
<li>if there is no setup fixture, then the teardown fixture is not run.</li>
<li>whether or not the tests succeed, the teardown fixture is run.</li>
<li>all tests are executed even if some of them fail.</li>
</ul>
</blockquote>
</div>
<div class="section">
<h3><a class="toc-backref" href="#id39" id="debugging-test-discovery" name="debugging-test-discovery">Debugging test discovery</a></h3>
<p>nose can only execute tests that it <em>finds</em>.  If you're creating a new
test suite, it's relatively easy to make sure that nose finds all your
tests -- just stick a few <tt class="docutils literal"><span class="pre">assert</span> <span class="pre">0</span></tt> statements in each new module,
and if nose doesn't kick up an error it's not running those tests!
It's more difficult when you're retrofitting an existing test suite to
run inside of nose; in the extreme case, you may need to write a plugin
or modify the top-level nose logic to find the existing tests.</p>
<p>The main problem I've run into is that nose will only find tests that
are properly named <em>and</em> within directory or package hierarchies that
it's actually traversing!  So placing your test modules under the
directory <tt class="docutils literal"><span class="pre">my_favorite_code</span></tt> won't work, because nose will not even
enter that directory.  However, if you make <tt class="docutils literal"><span class="pre">my_favorite_code</span></tt> a
<em>package</em>, then nose <em>will</em> find your tests because it traverses over
modules within packages.</p>
<p>In any case, using the <tt class="docutils literal"><span class="pre">-vv</span></tt> flag gives you verbose output from
nose's test discovery algorithm.  This will tell you whether or not
nose is even looking in the right place(s) to find your tests.</p>
</div>
</div>
<div class="section">
<h2><a class="toc-backref" href="#id40" id="the-nose-command-line" name="the-nose-command-line">The nose command line</a></h2>
<p>Apart from the plugins, there are only a few options that I use
regularly.</p>
<div class="section">
<h3><a class="toc-backref" href="#id41" id="w-specifying-the-working-directory" name="w-specifying-the-working-directory">-w: Specifying the working directory</a></h3>
<p>nose only looks for tests in one place.  The -w flag lets you specify
that location; e.g.</p>
<pre class="literal-block">
nosetests -w simple/
</pre>
<p>will run only those tests in the directory <tt class="docutils literal"><span class="pre">./simple/</span></tt>.</p>
<p>As of the latest development version (October 2006) you can specify
multiple working directories on the command line:</p>
<pre class="literal-block">
nosetests -w simple/ -w basic/
</pre>
<p>See <cite>Running nose programmatically</cite> for an example of how to specify
multiple working directories using Python, in nose 0.9.</p>
</div>
<div class="section">
<h3><a class="toc-backref" href="#id42" id="s-not-capturing-stdout" name="s-not-capturing-stdout">-s: Not capturing stdout</a></h3>
<p>By default, nose captures all output and only presents stdout from tests
that fail.  By specifying '-s', you can turn this behavior off.</p>
</div>
<div class="section">
<h3><a class="toc-backref" href="#id43" id="v-info-and-debugging-output" name="v-info-and-debugging-output">-v: Info and debugging output</a></h3>
<p>nose is intentionally pretty terse.  If you want to see what tests are
being run, use '-v'.</p>
</div>
<div class="section">
<h3><a class="toc-backref" href="#id44" id="specifying-a-list-of-tests-to-run" name="specifying-a-list-of-tests-to-run">Specifying a list of tests to run</a></h3>
<p>nose lets you specify a set of tests on the command line; only tests
that are <em>both</em> discovered <em>and</em> in this set of tests will be run.
For example,</p>
<pre class="literal-block">
nosetests -w simple tests/test_stuff.py:test_b
</pre>
<p>only runs the function <tt class="docutils literal"><span class="pre">test_b</span></tt> found in <tt class="docutils literal"><span class="pre">simple/tests/test_stuff.py</span></tt>.</p>
</div>
</div>
<div class="section">
<h2><a class="toc-backref" href="#id45" id="running-doctests-in-nose" name="running-doctests-in-nose">Running doctests in nose</a></h2>
<p><a class="reference" href="http://docs.python.org/lib/module-doctest.html">Doctests</a> are a nice way to test individual Python functions in a
convenient documentation format.  For example, the docstring for
the function <tt class="docutils literal"><span class="pre">multiply</span></tt>, below, contains a doctest:</p>
<pre class="literal-block">
def multiply(a, b):
  &quot;&quot;&quot;
  'multiply' multiplies two numbers and returns the result.

  &gt;&gt;&gt; multiply(5, 10)               # doctest: +SKIP
  50
  &gt;&gt;&gt; multiply(-1, 1)               # doctest: +SKIP
  -1
  &gt;&gt;&gt; multiply(0.5, 1.5)            # doctest: +SKIP
  0.75
  &quot;&quot;&quot;
  return a*b
</pre>
<p>(Ignore the SKIP pragmas; they're put in so that this file itself can
be run through doctest without failing...)</p>
<p>The doctest module (part of the Python standard module) scans through
all of the docstrings in a package or module, executes any line
starting with a <tt class="docutils literal"><span class="pre">&gt;&gt;&gt;</span></tt>, and compares the actual output with the
expected output contained in the docstring.</p>
<p>Typically you run these directly on a module level, using the sort of
<tt class="docutils literal"><span class="pre">__main__</span></tt> hack I showed above.  The doctest plug-in for nose adds
doctest discovery into nose -- all non-test packages are scanned for
doctests, and any doctests are executed along with the rest of the
tests.</p>
<p>To use the doctest plug-in, go to the directory containing the modules
and packages you want searched and do</p>
<pre class="literal-block">
nosetests --with-doctest
</pre>
<p>All of the doctests will be automatically found and executed.  Some
example doctests are included with the demo code, under <tt class="docutils literal"><span class="pre">basic</span></tt>; you can run them
like so:</p>
<pre class="literal-block">
% nosetests -w basic/ --with-doctest -v
doctest of app_package.stuff.function_with_doctest ... ok
...
</pre>
<p>Note that by default nose only looks for doctests in <em>non-test</em>
code.  You can add <tt class="docutils literal"><span class="pre">--doctest-tests</span></tt> to the command line to search
for doctests in your test code as well.</p>
<p>The doctest plugin gives you a nice way to combine your various
low-level tests (e.g. both unit tests and doctests) within one single
nose run; it also means that you're less likely to forget about running
your doctests!</p>
</div>
<div class="section">
<h2><a class="toc-backref" href="#id46" id="the-attrib-plug-in-selectively-running-subsets-of-tests" name="the-attrib-plug-in-selectively-running-subsets-of-tests">The 'attrib' plug-in -- selectively running subsets of tests</a></h2>
<p>The attrib extension module lets you flexibly select subsets of tests
based on test <em>attributes</em> -- literally, Python variables attached
to individual tests.</p>
<p>Suppose you had the following code (in <tt class="docutils literal"><span class="pre">attr/test_attr.py</span></tt>):</p>
<pre class="literal-block">
def testme1():
    assert 1

testme1.will_fail = False

def testme2():
    assert 0

testme2.will_fail = True

def testme3():
    assert 1
</pre>
<p>Using the attrib extension, you can select a subset of these tests
based on the attribute <tt class="docutils literal"><span class="pre">will_fail</span></tt>.  For example, <tt class="docutils literal"><span class="pre">nosetests</span> <span class="pre">-a</span>
<span class="pre">will_fail</span></tt> will run only <tt class="docutils literal"><span class="pre">testme2</span></tt>, while <tt class="docutils literal"><span class="pre">nosetests</span> <span class="pre">-a</span>
<span class="pre">\!will_fail</span></tt> will run both <tt class="docutils literal"><span class="pre">testme1</span></tt> and <tt class="docutils literal"><span class="pre">testme3</span></tt>.  You can also
specify precise values, e.g. <tt class="docutils literal"><span class="pre">nosetests</span> <span class="pre">-a</span> <span class="pre">will_fail=False</span></tt> will run
only <tt class="docutils literal"><span class="pre">testme1</span></tt>, because <tt class="docutils literal"><span class="pre">testme3</span></tt> doesn't have the attribute <tt class="docutils literal"><span class="pre">will_fail</span></tt>.</p>
<p>You can also tag tests with <em>lists</em> of attributes, as in <tt class="docutils literal"><span class="pre">attr/test_attr2.py</span></tt>:</p>
<pre class="literal-block">
def testme5():
    assert 1

testme5.tags = ['a', 'b']

def testme6():
    assert 1

testme6.tags = ['a', 'c']
</pre>
<p>Then <tt class="docutils literal"><span class="pre">nosetests</span> <span class="pre">-a</span> <span class="pre">tags=a</span></tt> will run both <tt class="docutils literal"><span class="pre">testme5</span></tt> and <tt class="docutils literal"><span class="pre">testme6</span></tt>,
while <tt class="docutils literal"><span class="pre">nosetests</span> <span class="pre">-a</span> <span class="pre">tags=b</span></tt> will run only <tt class="docutils literal"><span class="pre">testme5</span></tt>.</p>
<p>Attribute tags also work on classes and methods as you might expect.  In
<tt class="docutils literal"><span class="pre">attr/test_attr3.py</span></tt>, the following code</p>
<pre class="literal-block">
class TestMe:
    x = True

    def test_case1(self):
        assert 1

    def test_case2(self):
        assert 1

    test_case2.x = False
</pre>
<p>lets you run both <tt class="docutils literal"><span class="pre">test_case1</span></tt> (with <tt class="docutils literal"><span class="pre">-a</span> <span class="pre">x</span></tt>) and <tt class="docutils literal"><span class="pre">test_case2</span></tt>
(with <tt class="docutils literal"><span class="pre">-a</span> <span class="pre">\!x</span></tt>); here, methods inherit the attributes of their
parent class, but can override the class attributes with
method-specific attributes.</p>
</div>
<div class="section">
<h2><a class="toc-backref" href="#id47" id="running-nose-programmatically" name="running-nose-programmatically">Running nose programmatically</a></h2>
<p>nose has a friendly top-level API which makes it accessible to Python
programs.  You can run nose inside your own code by doing this:</p>
<pre class="literal-block">
import nose

### configure paths, etc here

nose.run()

### do other stuff here
</pre>
<p>By default nose will pick up on <tt class="docutils literal"><span class="pre">sys.argv</span></tt>; if you want to pass in
your own arguments, use <tt class="docutils literal"><span class="pre">nose.run(argv=args)</span></tt>.  You can also
override the default test collector, test runner, test loader, and
environment settings at this level.  This makes it convenient to add
in certain types of new behavior; see <tt class="docutils literal"><span class="pre">multihome/multihome-nose</span></tt> for
a script that lets you specify multiple &quot;test home directories&quot; by
overriding the test collector.</p>
<p>There are a few caveats to mention about using the top-level nose
commands.  First, be sure to use <tt class="docutils literal"><span class="pre">nose.run</span></tt>, not <tt class="docutils literal"><span class="pre">nose.main</span></tt> --
<tt class="docutils literal"><span class="pre">nose.main</span></tt> will exit after running the tests (although you can wrap
it in a 'try/finally' if you insist).  Second, in the current version
of nose (0.9b1), <tt class="docutils literal"><span class="pre">nose.run</span></tt> swipes <tt class="docutils literal"><span class="pre">sys.stdout</span></tt>, so <tt class="docutils literal"><span class="pre">print</span></tt> will
not yield any output after <tt class="docutils literal"><span class="pre">nose.run</span></tt> completes.  (This should be
fixed soon.)</p>
</div>
<div class="section">
<h2><a class="toc-backref" href="#id48" id="writing-plug-ins-a-simple-guide" name="writing-plug-ins-a-simple-guide">Writing plug-ins -- a simple guide</a></h2>
<p>As nice as nose already is, the plugin system is probably the best
thing about it.  nose uses the setuptools API to load all registered
nose plugins, allowing you to install 3rd party plugins quickly and
easily; plugins can modify or override output handling, test
discovery, and test execution.</p>
<p>nose comes with a couple of plugins that demonstrate the power of the
plugin API; I've discussed two (the attrib and doctest plugins) above.
I've also written a few, as part of the <a class="reference" href="http://darcs.idyll.org/~t/projects/pinocchio/doc/index.html">pinocchio</a> nose extensions package.</p>
<p>Here are a few tips and tricks for writing plugins.</p>
<blockquote>
<ul>
<li><p class="first">read through the <tt class="docutils literal"><span class="pre">nose.plugins.IPluginInterface</span></tt> code a few times.</p>
</li>
<li><p class="first">for the <tt class="docutils literal"><span class="pre">want*</span></tt> functions (<tt class="docutils literal"><span class="pre">wantClass</span></tt>, <tt class="docutils literal"><span class="pre">wantMethod</span></tt>, etc.)
you need to know:</p>
<blockquote>
<ul class="simple">
<li>a return value of True indicates that your plugin wants this item.</li>
<li>a return value of False indicates that your plugin doesn't want this item.</li>
<li>a return value of None indicates that your plugin doesn't care about this item.</li>
</ul>
</blockquote>
<p>Also note that plugins aren't guaranteed to be run in any particular order,
so you have to order them yourself if you need this.  See the
<tt class="docutils literal"><span class="pre">pinocchio.decorator</span></tt> module (part of <a class="reference" href="http://darcs.idyll.org/~t/projects/pinocchio/doc/index.html">pinocchio</a>) for an example.</p>
</li>
<li><p class="first">abuse stderr.  As much as I like the logging package, it can
confuse matters by capturing output in ways I don't fully
understand (or at least don't want to have to configure for
debugging purposes).  While you're working on your plugin, put
<tt class="docutils literal"><span class="pre">import</span> <span class="pre">sys;</span> <span class="pre">err</span> <span class="pre">=</span> <span class="pre">sys.stderr</span></tt> at the top of your plugin module,
and then use <tt class="docutils literal"><span class="pre">err.write</span></tt> to produce debugging output.</p>
</li>
<li><p class="first">notwithstanding the stderr advice, <tt class="docutils literal"><span class="pre">-vv</span></tt> is your friend -- it will tell
you that your test file isn't even being examined for tests, and it will
also tell you what order things are being run in.</p>
</li>
<li><p class="first">write your initial plugin code by simply copying <tt class="docutils literal"><span class="pre">nose.plugins.attrib</span></tt>
and deleting everything that's not generic.  This greatly simplifies
getting your plugin loaded &amp; functioning.</p>
</li>
<li><p class="first">to register your plugin, you need this code in e.g. a file called 'setup.py'</p>
<pre class="literal-block">
from setuptools import setup

setup(
    name='my_nose_plugin',
    packages = ['my_nose_plugin'],
    entry_points = {
        'nose.plugins': [
            'pluginA = my_nose_plugin:pluginA',
            ]
        },
)
</pre>
<p>You can then install (and register) the plugin with <tt class="docutils literal"><span class="pre">easy_install</span> <span class="pre">.</span></tt>,
run in the directory containing 'setup.py'.</p>
</li>
</ul>
</blockquote>
</div>
<div class="section">
<h2><a class="toc-backref" href="#id49" id="nose-caveats-let-the-buyer-beware-occasionally" name="nose-caveats-let-the-buyer-beware-occasionally">nose caveats -- let the buyer beware, occasionally</a></h2>
<p>I've been using nose fairly seriously for a while now, on multiple
projects.  The two most frustrating problems I've had are with the
output capture (mentioned above, in <cite>Running nose programmatically</cite>)
and a situation involving the <tt class="docutils literal"><span class="pre">logging</span></tt> module.  The output capture
problem is easily taken care of, once you're aware of it -- just be
sure to save sys.stdout before running any nose code.  The logging
module problem cropped up when converting an existing unit test suite
over to nose: the code tested an application that used the <tt class="docutils literal"><span class="pre">logging</span></tt>
module, and reconfigured logging so that nose's output didn't show up.
This frustrated my attempts to trace test discovery to no end -- as
far as I could tell, nose was simply stopping test discovery at a
certain point!  I doubt there's a general solution to this, but I
thought I'd mention it.</p>
</div>
<div class="section">
<h2><a class="toc-backref" href="#id50" id="credits" name="credits">Credits</a></h2>
<p>Jason Pellerin, besides for being the author of nose, has been very
helpful in answering questions!  Terry Peppers and Chad Whitacre
kindly sent me errata.</p>
<!-- This introduction is Copyright (C) 2006, C. Titus Brown, -->
<!-- titus@idyll.org.  Please don't redistribute or publish it without his -->
<!-- express permission. -->
<!-- Comments, corrections, and additions are welcome, of course! -->
</div>
</div>
<div class="section">
<h1><a class="toc-backref" href="#id51" id="idiomatic-python-revisited" name="idiomatic-python-revisited">Idiomatic Python revisited</a></h1>
<div class="section">
<h2><a class="toc-backref" href="#id52" id="sets" name="sets">sets</a></h2>
<p>Sets recently (2.4?) migrated from a stdlib component into a default type.
They're exactly what you think: unordered collections of values.</p>
<pre class="doctest-block">
&gt;&gt;&gt; s = set((1, 2, 3, 4, 5))
&gt;&gt;&gt; t = set((4, 5, 6))
&gt;&gt;&gt; print s
set([1, 2, 3, 4, 5])
</pre>
<p>You can union and intersect them:</p>
<pre class="doctest-block">
&gt;&gt;&gt; print s.union(t)
set([1, 2, 3, 4, 5, 6])
&gt;&gt;&gt; print s.intersection(t)
set([4, 5])
</pre>
<p>And you can also check for supersets and subsets:</p>
<pre class="doctest-block">
&gt;&gt;&gt; u = set((4, 5, 6, 7))
&gt;&gt;&gt; print t.issubset(u)
True
&gt;&gt;&gt; print u.issubset(t)
False
</pre>
<p>One more note: you can convert between sets and lists pretty easily:</p>
<pre class="doctest-block">
&gt;&gt;&gt; sl = list(s)
&gt;&gt;&gt; ss = set(sl)
</pre>
</div>
<div class="section">
<h2><a class="toc-backref" href="#id53" id="any-and-all" name="any-and-all"><tt class="docutils literal"><span class="pre">any</span></tt> and <tt class="docutils literal"><span class="pre">all</span></tt></a></h2>
<p><tt class="docutils literal"><span class="pre">all</span></tt> and <tt class="docutils literal"><span class="pre">any</span></tt> are two new functions in Python that work with iterables
(e.g. lists, generators, etc.).  <tt class="docutils literal"><span class="pre">any</span></tt> returns True if <em>any</em> element of
the iterable is True (and False otherwise); <tt class="docutils literal"><span class="pre">all</span></tt> returns True if <em>all</em>
elements of the iterable are True (and False otherwise).</p>
<p>Consider:</p>
<pre class="doctest-block">
&gt;&gt;&gt; x = [ True, False ]
&gt;&gt;&gt; print any(x)
True
&gt;&gt;&gt; print all(x)
False
</pre>
<pre class="doctest-block">
&gt;&gt;&gt; y = [ True, True ]
&gt;&gt;&gt; print any(y)
True
&gt;&gt;&gt; print all(y)
True
</pre>
<pre class="doctest-block">
&gt;&gt;&gt; z = [ False, False ]
&gt;&gt;&gt; print any(z)
False
&gt;&gt;&gt; print all(z)
False
</pre>
</div>
<div class="section">
<h2><a class="toc-backref" href="#id54" id="exceptions-and-exception-hierarchies" name="exceptions-and-exception-hierarchies">Exceptions and exception hierarchies</a></h2>
<p>You're all familiar with exception handling using try/except:</p>
<pre class="doctest-block">
&gt;&gt;&gt; x = [1, 2, 3, 4, 5]
&gt;&gt;&gt; x[10]
Traceback (most recent call last):
   ...
IndexError: list index out of range
</pre>
<p>You can catch all exceptions quite easily:</p>
<pre class="doctest-block">
&gt;&gt;&gt; try:
...   y = x[10]
... except:
...   y = None
</pre>
<p>but this is considered bad form, because of the potential for over-broad
exception handling:</p>
<pre class="doctest-block">
&gt;&gt;&gt; try:
...   y = x[&quot;10&quot;]
... except:
...   y = None
</pre>
<p>In general, try to catch the exception most specific to your code:</p>
<pre class="doctest-block">
&gt;&gt;&gt; try:
...   y = x[10]
... except IndexError:
...   y = None
</pre>
<p>...because then you will see the errors you didn't plan for:</p>
<pre class="doctest-block">
&gt;&gt;&gt; try:
...   y = x[&quot;10&quot;]
... except IndexError:
...   y = None
Traceback (most recent call last):
   ...
TypeError: list indices must be integers
</pre>
<p>Incidentally, you can re-raise exceptions, potentially after doing
something else:</p>
<pre class="doctest-block">
&gt;&gt;&gt; try:
...   y = x[10]
... except IndexError:
...   # do something else here #
...   raise
Traceback (most recent call last):
   ...
IndexError: list index out of range
</pre>
<p>There are some special exceptions to be aware of.  Two that I run into a lot
are SystemExit and KeyboardInterrupt.  KeyboardInterrupt is what is raised
when a CTRL-C interrupts Python; you can handle it and exit gracefully if
you like, e.g.</p>
<pre class="doctest-block">
&gt;&gt;&gt; try:
...   # do_some_long_running_task()
...   pass
... except KeyboardInterrupt:
...   sys.exit(0)
</pre>
<p>which is sometimes nice for things like Web servers (more on that tomorrow).</p>
<p>SystemExit is also pretty useful.  It's actually an exception raised by
<tt class="docutils literal"><span class="pre">sys.exit</span></tt>, i.e.</p>
<pre class="doctest-block">
&gt;&gt;&gt; import sys
&gt;&gt;&gt; try:
...   sys.exit(0)
... except SystemExit:
...   pass
</pre>
<p>means that sys.exit has no effect!  You can also raise SystemExit instead
of calling sys.exit, e.g.</p>
<pre class="doctest-block">
&gt;&gt;&gt; raise SystemExit(0)
Traceback (most recent call last):
   ...
SystemExit: 0
</pre>
<p>is equivalent to <tt class="docutils literal"><span class="pre">sys.exit(0)</span></tt>:</p>
<pre class="doctest-block">
&gt;&gt;&gt; sys.exit(0)
Traceback (most recent call last):
   ...
SystemExit: 0
</pre>
<p>Another nice feature of exceptions is exception hierarchies.
Exceptions are just classes that derive from <tt class="docutils literal"><span class="pre">Exception</span></tt>, and you
can catch exceptions based on their base classes.  So, for example,
you can catch most standard errors by catching the StandardError
exception, from which e.g. IndexError inherits:</p>
<pre class="doctest-block">
&gt;&gt;&gt; print issubclass(IndexError, StandardError)
True
</pre>
<pre class="doctest-block">
&gt;&gt;&gt; try:
...   y = x[10]
... except StandardError:
...   y = None
</pre>
<p>You can also catch some exceptions more specifically than others.  For
example, KeyboardInterrupt inherits from Exception, and some times you
want to catch KeyboardInterrupts while ignoring all other exceptions:</p>
<pre class="doctest-block">
&gt;&gt;&gt; try:
...   # ...
...   pass
... except KeyboardInterrupt:
...   raise
... except Exception:
...   pass
</pre>
<p>Note that if you want to print out the error, you can do coerce a string
out of the exception to present to the user:</p>
<pre class="doctest-block">
&gt;&gt;&gt; try:
...   y = x[10]
... except Exception, e:
...   print 'CAUGHT EXCEPTION!', str(e)
CAUGHT EXCEPTION! list index out of range
</pre>
<p>Last but not least, you can define your own exceptions and exception
hierarchies:</p>
<pre class="doctest-block">
&gt;&gt;&gt; class MyFavoriteException(Exception):
...   pass
&gt;&gt;&gt; raise MyFavoriteException
Traceback (most recent call last):
   ...
MyFavoriteException
</pre>
<p>I haven't used this much myself, but it is invaluable when you are writing
packages that have a lot of different detailed exceptions that you might
want to let users handle.</p>
<p>(By default, I usually raise a simple Exception in my own code.)</p>
<p>Oh, one more note: AssertionError.  Remember assert?</p>
<pre class="doctest-block">
&gt;&gt;&gt; assert 0
Traceback (most recent call last):
   ...
AssertionError
</pre>
<p>Yep, it raises an AssertionError that you can catch, if you REALLY want to...</p>
</div>
<div class="section">
<h2><a class="toc-backref" href="#id55" id="function-decorators" name="function-decorators">Function Decorators</a></h2>
<p>Function decorators are a strange beast that I tend to use only in my
testing code and not in my actual application code.  Briefly, function
decorators are functions that take functions as arguments, and return
other functions.  Confused?  Let's see a simple example that makes
sure that no keyword argument named 'something' ever gets passed into
a function:</p>
<pre class="doctest-block">
&gt;&gt;&gt; def my_decorator(fn):
...
...   def new_fn(*args, **kwargs):
...      if 'something' in kwargs:
...         print 'REMOVING', kwargs['something']
...         del kwargs['something']
...      return fn(*args, **kwargs)
...
...   return new_fn
</pre>
<p>To apply this decorator, use this funny &#64; syntax:</p>
<pre class="doctest-block">
&gt;&gt;&gt; &#64;my_decorator
... def some_function(a=5, b=6, something=None, c=7):
...   print a, b, something, c
</pre>
<p>OK, now <tt class="docutils literal"><span class="pre">some_function</span></tt> has been invisibly replaced with the result of
<tt class="docutils literal"><span class="pre">my_decorator</span></tt>, which is going to be <tt class="docutils literal"><span class="pre">new_fn</span></tt>.  Let's see the result:</p>
<pre class="doctest-block">
&gt;&gt;&gt; some_function(something='MADE IT')
REMOVING MADE IT
5 6 None 7
</pre>
<p>Mind you, without the decorator, the function does exactly what you expect:</p>
<pre class="doctest-block">
&gt;&gt;&gt; def some_function(a=5, b=6, something=None, c=7):
...   print a, b, something, c
&gt;&gt;&gt; some_function(something='MADE IT')
5 6 MADE IT 7
</pre>
<p>OK, so this is a bit weird.  What possible uses are there for this??</p>
<p>Here are three example uses:</p>
<p>First, synchronized functions like in Java.  Suppose you had a bunch
of functions (f1, f2, f3...) that could not be called concurrently, so
you wanted to play locks around them.  You could do this with decorators:</p>
<pre class="doctest-block">
&gt;&gt;&gt; import threading
&gt;&gt;&gt; def synchronized(fn):
...   lock = threading.Lock()
...
...   def new_fn(*args, **kwargs):
...      lock.acquire()
...      print 'lock acquired'
...      result = fn(*args, **kwargs)
...      lock.release()
...      print 'lock released'
...      return result
...
...   return new_fn
</pre>
<p>and then when you define your functions, they will be locked:</p>
<pre class="doctest-block">
&gt;&gt;&gt; &#64;synchronized
... def f1():
...   print 'in f1'
&gt;&gt;&gt; f1()
lock acquired
in f1
lock released
</pre>
<p>Second, adding attributes to functions.  (This is why I use them in my testing
code sometimes.)</p>
<pre class="doctest-block">
&gt;&gt;&gt; def attrs(**kwds):
...    def decorate(f):
...        for k in kwds:
...            setattr(f, k, kwds[k])
...        return f
...    return decorate
</pre>
<pre class="doctest-block">
&gt;&gt;&gt; &#64;attrs(versionadded=&quot;2.2&quot;,
...       author=&quot;Guido van Rossum&quot;)
... def mymethod(f):
...    pass
</pre>
<pre class="doctest-block">
&gt;&gt;&gt; print mymethod.versionadded
2.2
&gt;&gt;&gt; print mymethod.author
Guido van Rossum
</pre>
<p>Third, memoize/caching of results.  Here's a really simple example; you can
find much more general ones online, in particular on the <a class="reference" href="http://www.activestate.com/ASPN/Python/Cookbook/">Python Cookbook
site</a>.</p>
<p>Imagine that you have a CPU-expensive one-parameter function:</p>
<pre class="doctest-block">
&gt;&gt;&gt; def expensive(n):
...   print 'IN EXPENSIVE', n
...   # do something expensive here, like calculate n'th prime
</pre>
<p>You could write a caching decorator to wrap this function and record
results transparently:</p>
<pre class="doctest-block">
&gt;&gt;&gt; def simple_cache(fn):
...   cache = {}
...
...   def new_fn(n):
...      if n in cache:
...         print 'FOUND IN CACHE; RETURNING'
...         return cache[n]
...
...      # otherwise, call function &amp; record value
...      val = fn(n)
...      cache[n] = val
...      return val
...
...   return new_fn
</pre>
<p>Then use this as a decorator to wrap the expensive function:</p>
<pre class="doctest-block">
&gt;&gt;&gt; &#64;simple_cache
... def expensive(n):
...   print 'IN THE EXPENSIVE FN:', n
...   return n**2
</pre>
<p>Now, when you call this function twice with the same argument, if will
only do the calculation once; the second time, the function call will be
intercepted and the cached value will be returned.</p>
<pre class="doctest-block">
&gt;&gt;&gt; expensive(55)
IN THE EXPENSIVE FN: 55
3025
&gt;&gt;&gt; expensive(55)
FOUND IN CACHE; RETURNING
3025
</pre>
<p>Check out Michele Simionato's writeup of decorators <a class="reference" href="http://www.phyast.pitt.edu/~micheles/python/documentation.html">here</a>
for lots more information on decorators.</p>
</div>
<div class="section">
<h2><a class="toc-backref" href="#id56" id="try-finally" name="try-finally">try/finally</a></h2>
<p>Finally, we come to try/finally!</p>
<p>The syntax of try/finally is just like try/except:</p>
<pre class="literal-block">
try:
   do_something()
finally:
   do_something_else()
</pre>
<p>The purpose of try/finally is to ensure that something is done, whether or
not an exception is raised:</p>
<pre class="doctest-block">
&gt;&gt;&gt; x = [0, 1, 2]
&gt;&gt;&gt; try:
...   y = x[5]
... finally:
...   x.append('something')
Traceback (most recent call last):
   ...
IndexError: list index out of range
</pre>
<pre class="doctest-block">
&gt;&gt;&gt; print x
[0, 1, 2, 'something']
</pre>
<p>(It's actually semantically equivalent to:</p>
<pre class="doctest-block">
&gt;&gt;&gt; try:
...   y = x[5]
... except IndexError:
...   x.append('something')
...   raise
Traceback (most recent call last):
   ...
IndexError: list index out of range
</pre>
<p>but it's a bit cleaner, because the exception doesn't have to be re-raised
and you don't have to catch a specific exception type.)</p>
<p>Well, why do you need this?  Let's think about locking.  First, get a lock:</p>
<pre class="doctest-block">
&gt;&gt;&gt; import threading
&gt;&gt;&gt; lock = threading.Lock()
</pre>
<p>Now, if you're locking something, you want to be darn sure to <em>release</em>
that lock.  But what if an exception is raised right in the middle?</p>
<pre class="doctest-block">
&gt;&gt;&gt; def fn():
...    print 'acquiring lock'
...    lock.acquire()
...    y = x[5]
...    print 'releasing lock'
...    lock.release()
&gt;&gt;&gt; try:
...    fn()
... except IndexError:
...   pass
acquiring lock
</pre>
<p>Note that 'releasing lock' is never printed: 'lock' is now left in a
locked state, and next time you run 'fn' you will hang the program
forever.  Oops.</p>
<p>You can fix this with try/finally:</p>
<pre class="doctest-block">
&gt;&gt;&gt; lock = threading.Lock()             # gotta trash the previous lock, or hang!
&gt;&gt;&gt; def fn():
...    print 'acquiring lock'
...    lock.acquire()
...    try:
...       y = x[5]
...    finally:
...       print 'releasing lock'
...       lock.release()
&gt;&gt;&gt; try:
...   fn()
... except IndexError:
...   pass
acquiring lock
releasing lock
</pre>
</div>
<div class="section">
<h2><a class="toc-backref" href="#id57" id="function-arguments-and-wrapping-functions" name="function-arguments-and-wrapping-functions">Function arguments, and wrapping functions</a></h2>
<p>You may have noticed above (in the section on decorators) that we wrapped
functions using this notation:</p>
<pre class="literal-block">
def wrapper_fn(*args, **kwargs):
    return fn(*args, **kwargs)
</pre>
<p>(This takes the place of the old 'apply'.)  What does this do?</p>
<p>Here, *args assigns all of the positional arguments to a tuple
'args', and '**kwargs' assigns all of the keyword arguments to a
dictionary 'kwargs':</p>
<pre class="doctest-block">
&gt;&gt;&gt; def print_me(*args, **kwargs):
...   print 'args is:', args
...   print 'kwargs is:', kwargs
</pre>
<pre class="doctest-block">
&gt;&gt;&gt; print_me(5, 6, 7, test='me', arg2=None)
args is: (5, 6, 7)
kwargs is: {'test': 'me', 'arg2': None}
</pre>
<p>When a function is called with this notation, the args and kwargs are
unpacked appropriately and passed into the function.  For example,
the function <tt class="docutils literal"><span class="pre">test_call</span></tt></p>
<pre class="doctest-block">
&gt;&gt;&gt; def test_call(a, b, c, x=1, y=2, z=3):
...   print a, b, c, x, y, z
</pre>
<p>can be called with a tuple of three args (matching 'a', 'b', 'c'):</p>
<pre class="doctest-block">
&gt;&gt;&gt; tuple_in = (5, 6, 7)
&gt;&gt;&gt; test_call(*tuple_in)
5 6 7 1 2 3
</pre>
<p>with some optional keyword args:</p>
<pre class="doctest-block">
&gt;&gt;&gt; d = { 'x' : 'hello', 'y' : 'world' }
&gt;&gt;&gt; test_call(*tuple_in, **d)
5 6 7 hello world 3
</pre>
<p>Incidentally, this lets you implement the 'dict' constructor in one
line!</p>
<pre class="doctest-block">
&gt;&gt;&gt; def dict_replacement(**kwargs):
...    return kwargs
</pre>
</div>
</div>
<div class="section">
<h1><a class="toc-backref" href="#id58" id="measuring-and-increasing-performance" name="measuring-and-increasing-performance">Measuring and Increasing Performance</a></h1>
<p>&quot;Premature optimization is the root of all evil (or at least most of
it) in programming.&quot;  Donald Knuth.</p>
<p>In other words, know thy code!  The only way to find performance
bottlenecks is to profile your code.  Unfortunately, the situation is
a bit more complex in Python than you would like it to be: see
<a class="reference" href="http://docs.python.org/lib/profile.html">http://docs.python.org/lib/profile.html</a>.  Briefly, there are three
(!?) standard profiling systems that come with Python: profile,
cProfile (only since python 2.5!), and hotshot (thought note that
profile and cProfile are Python and C implementations of the same
API).  There is also a separately maintained one called statprof, that
I nominally maintain.</p>
<p>The ones included with Python are deterministic profilers, while
statprof is a statistical profiler.  What's the difference? To steal
from the Python docs:</p>
<blockquote>
Deterministic profiling is meant to reflect the fact that all function
call, function return, and exception events are monitored, and precise
timings are made for the intervals between these events (during which
time the user's code is executing). In contrast, statistical profiling
randomly samples the effective instruction pointer, and deduces where
time is being spent. The latter technique traditionally involves less
overhead (as the code does not need to be instrumented), but provides
only relative indications of where time is being spent.</blockquote>
<p>Let's go to the examples.  Suppose we have two functions 'count1'
and 'count2', and we want to run both and see where time is spent.</p>
<hr class="docutils" />
<p>Here's some example hotshot code:</p>
<pre class="literal-block">
import hotshot, hotshot.stats
prof = hotshot.Profile('hotshot.prof')
prof.runcall(count1)
prof.runcall(count2)
prof.close()
stats = hotshot.stats.load('hotshot.prof')
stats.sort_stats('time', 'calls')
stats.print_stats(20)
</pre>
<p>and the resulting output:</p>
<pre class="literal-block">
      2 function calls in 5.769 CPU seconds

Ordered by: internal time, call count

ncalls  tottime  percall  cumtime  percall filename:lineno(function)
     1    4.335    4.335    4.335    4.335 count.py:8(count2)
     1    1.434    1.434    1.434    1.434 count.py:1(count1)
     0    0.000             0.000          profile:0(profiler)
</pre>
<hr class="docutils" />
<p>Here's some example cProfile code:</p>
<pre class="literal-block">
def runboth():
    count1()
    count2()

import cProfile, pstats
cProfile.run('runboth()', 'cprof.out')

p = pstats.Stats('cprof.out')
p.sort_stats('time').print_stats(10)
</pre>
<p>and the resulting output:</p>
<pre class="literal-block">
Wed Jun 13 00:11:55 2007    cprof.out

         7 function calls in 5.643 CPU seconds

   Ordered by: internal time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
        1    3.817    3.817    4.194    4.194 count.py:8(count2)
        1    1.282    1.282    1.450    1.450 count.py:1(count1)
        2    0.545    0.272    0.545    0.272 {range}
        1    0.000    0.000    5.643    5.643 run-cprofile:8(runboth)
        1    0.000    0.000    5.643    5.643 &lt;string&gt;:1(&lt;module&gt;)
        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}
</pre>
<hr class="docutils" />
<p>And here's an example of statprof, the statistical profiler:</p>
<pre class="literal-block">
import statprof
statprof.start()
count1()
count2()
statprof.stop()
statprof.display()
</pre>
<p>And the output:</p>
<pre class="literal-block">
  %   cumulative      self
 time    seconds   seconds  name
 74.66      4.10      4.10  count.py:8:count2
 25.34      1.39      1.39  count.py:1:count1
  0.00      5.49      0.00  run-statprof:2:&lt;module&gt;
---
Sample count: 296
Total time: 5.490000 seconds
</pre>
<div class="section">
<h2><a class="toc-backref" href="#id59" id="which-profiler-should-you-use" name="which-profiler-should-you-use">Which profiler should you use?</a></h2>
<p>statprof used to report more accurate numbers than hotshot or
cProfile, because hotshot and cProfile had to instrument the code
(insert tracing statements, basically).  However, the numbers shown
above are pretty similar to each other and I'm not sure there's much
of a reason to choose between them any more.  So, I recommend starting
with cProfile, because it's the officially supported one.</p>
<p>One note -- none of these profilers really work all that well with
threads, for a variety of reasons.  You're best off doing performance
measurements on non-threaded code.</p>
</div>
<div class="section">
<h2><a class="toc-backref" href="#id60" id="measuring-code-snippets-with-timeit" name="measuring-code-snippets-with-timeit">Measuring code snippets with timeit</a></h2>
<p>There's also a simple timing tool called timeit:</p>
<pre class="literal-block">
from timeit import Timer
from count import *

t1 = Timer(&quot;count1()&quot;, &quot;from count import count1&quot;)
print 'count1:', t1.timeit(number=1)

t2 = Timer(&quot;count2()&quot;, &quot;from count import count2&quot;)
print 'count2:', t2.timeit(number=1)
</pre>
</div>
</div>
<div class="section">
<h1><a class="toc-backref" href="#id61" id="speeding-up-python" name="speeding-up-python">Speeding Up Python</a></h1>
<p>There are a couple of options for speeding up Python.</p>
<div class="section">
<h2><a class="toc-backref" href="#id62" id="psyco" name="psyco">psyco</a></h2>
<p>(Taken almost verbatim from the <a class="reference" href="http://psyco.sourceforge.net/introduction.html">psyco introduction</a>!)</p>
<p>psyco is a specializing compiler that lets you run your existing
Python code much faster, with <em>absolutely no change</em> in your source
code.  It acts like a just-in-time compiler by rewriting several
versions of your code blocks and then optimizing them by specializing
the variables they use.</p>
<p>The main benefit is that you get a 2-100x speed-up with an unmodified Python
interpreter and unmodified source code.  (You just need to import psyco.)</p>
<p>The main drawbacks are that it only runs on i386-compatible processors
(so, not PPC Macs) and it's a bit of a memory hog.</p>
<p>For example, if you use the prime number generator generator code (see
<a class="reference" href="idiomatic-python.txt">Idiomatic Python</a>) to generate all primes
under 100000, it takes about 10.4 seconds on my development server.
With psyco, it takes about 1.6 seconds (that's about a 6x speedup).
Even when doing less numerical stuff, I see at least a 2x speedup.</p>
<div class="section">
<h3><a class="toc-backref" href="#id63" id="installing-psyco" name="installing-psyco">Installing psyco</a></h3>
<p>(Note: psyco is an extension module and does not come in pre-compiled
form.  Therefore, you will need to have a Python-compatible C compiler
installed in order to install psyco.)</p>
<p>Grab the latest psyco snapshot from here:</p>
<pre class="literal-block">
http://psyco.sourceforge.net/psycoguide/sources.html
</pre>
<p>unpack it, and run 'python setup.py install'.</p>
</div>
<div class="section">
<h3><a class="toc-backref" href="#id64" id="using-psyco" name="using-psyco">Using psyco</a></h3>
<p>Put the following code at the top of your __main__ Python script:</p>
<pre class="literal-block">
try:
   import psyco
   psyco.full()
except ImportError:
   pass
</pre>
<p>...and you're done.  (Yes, it's magic!)</p>
<p>The only place where psyco won't help you much is when you have
already recoded the CPU-intensive component of your code into an
extension module.</p>
</div>
</div>
<div class="section">
<h2><a class="toc-backref" href="#id65" id="pyrex" name="pyrex">pyrex</a></h2>
<p>pyrex is a Python-like language used to create C modules for Python.
You can use it for two purposes: to increase performance by
(re)writing your code in C (but with a friendly extension language),
and to make C libraries available to Python.</p>
<p>In the context of speeding things up, here's an example program:</p>
<pre class="literal-block">
def primes(int maxprime):
  cdef int n, k, i
  cdef int p[100000]
  result = []
  k = 0
  n = 2
  while n &lt; maxprime:
    i = 0

    # test against previous primes
    while i &lt; k and n % p[i] &lt;&gt; 0:
      i = i + 1

    # prime? if so, save.
    if i == k:
      p[k] = n
      k = k + 1
      result.append(n)
    n = n + 1

  return result
</pre>
<p>To compile this, you would execute:</p>
<pre class="literal-block">
pyrexc primes.pyx
gcc -c -fPIC -I /usr/local/include/python2.5 primes.c
gcc -shared primes.o -o primes.so
</pre>
<p>Or, more nicely, you can write a setup.py using some of the Pyrex
helper functions:</p>
<pre class="literal-block">
from distutils.core import setup
from distutils.extension import Extension
from Pyrex.Distutils import build_ext                # &lt;--

setup(
  name = &quot;primes&quot;,
  ext_modules=[
    Extension(&quot;primes&quot;, [&quot;primes.pyx&quot;], libraries = [])
    ],
  cmdclass = {'build_ext': build_ext}
)
</pre>
<p>A few notes:</p>
<blockquote>
<ul class="simple">
<li>'cdef' is a C definition statement</li>
<li>this is a &quot;python-alike&quot; language but not Python, per se ;)</li>
<li>pyrex does handle a lot of the nasty C extension stuff for you.</li>
</ul>
</blockquote>
<p>There's an excellent guide to Pyrex available online here:
<a class="reference" href="http://ldots.org/pyrex-guide/">http://ldots.org/pyrex-guide/</a>.</p>
<p>I haven't used Pyrex much myself, but I have a friend who swears by
it.  My concerns are that it's a &quot;C/Python-alike&quot; language but not C
or Python, and I have already memorized too many weird rules about too
many languages!</p>
<p>We'll encounter Pyrex a bit further down the road in the context of
linking existing C/C++ code into your own code.</p>
<!-- @CTB will we?? ;) -->
</div>
</div>
<div class="section">
<h1><a class="toc-backref" href="#id66" id="tools-to-help-you-work" name="tools-to-help-you-work">Tools to Help You Work</a></h1>
<div class="section">
<h2><a class="toc-backref" href="#id67" id="ipython" name="ipython">IPython</a></h2>
<p><a class="reference" href="http://ipython.scipy.org/moin/About">IPython</a> is an interactive
interpreter that aims to be a very convenient shell for working with
Python.</p>
<p>Features of note:</p>
<blockquote>
<ul class="simple">
<li>Tab completion</li>
<li>? and ?? help</li>
<li>history</li>
<li>CTRL-P search (in addition to standard CTRL-R/emacs)</li>
<li>use an editor to write stuff, and export stuff into an edtor</li>
<li>colored exception tracebacks</li>
<li>automatic function/parameter call stuff</li>
<li>auto-quoting with ','</li>
<li>'run' (similar to execfile) but with -n, -i</li>
</ul>
</blockquote>
<p>See <a class="reference" href="http://ipython.scipy.org/doc/manual/node4.html">Quick tips</a> for
even more of a laundry list!</p>
</div>
<div class="section">
<h2><a class="toc-backref" href="#id68" id="screen-and-vnc" name="screen-and-vnc">screen and VNC</a></h2>
<p>screen is a non-graphical tool for running multiple text windows in a single
login session.</p>
<p>Features:</p>
<blockquote>
<ul class="simple">
<li>multiple windows w/hotkey switching</li>
<li>copy/paste between windows</li>
<li>detach/resume</li>
</ul>
</blockquote>
<p>VNC is a (free) graphical tool for persistent X Windows sessions (and
Windows control, too).</p>
<p>To start:</p>
<pre class="literal-block">
% vncserver
</pre>
<p>WARNING: Running VNC on an open network is a big security risk!!</p>
</div>
<div class="section">
<h2><a class="toc-backref" href="#id69" id="trac" name="trac">Trac</a></h2>
<p>Trac is a really nice-looking and friendly project management Web site.
It integrates a Wiki with a version control repository browser, a
ticket management system, and some simple roadmap controls.</p>
<p>In particular, you can:</p>
<blockquote>
<ul class="simple">
<li>browse the source code repository</li>
<li>create tickets</li>
<li>link checkin comments to specific tickets, revisions, etc.</li>
<li>customize components, permissions, roadmaps, etc.</li>
<li>view project status</li>
</ul>
</blockquote>
<p>It integrates well with subversion, which is &quot;a better CVS&quot;.</p>
</div>
</div>
<div class="section">
<h1><a class="toc-backref" href="#id70" id="online-resources-for-python" name="online-resources-for-python">Online Resources for Python</a></h1>
<p>The obvious one: <a class="reference" href="http://www.python.org/">http://www.python.org/</a> (including, of course,
<a class="reference" href="http://docs.python.org/">http://docs.python.org/</a>).</p>
<p>The next most obvious one: comp.lang.python.announce /
<a class="reference" href="http://www.python.org/mailman/listinfo/python-announce-list">python-announce</a>.
This is a low traffic list that is really quite handy; note especially
a brief summary of postings called &quot;the Weekly Python-URL&quot;, which as
far as I can tell is only available on this list.</p>
<p><a class="reference" href="http://www.activestate.com/ASPN/Python/Cookbook/">The Python Cookbook</a>
is chock full of useful recipes; some of them have been extracted and
prettified in the O'Reilly Python Cookbook book, but they're all available
through the Cookbook site.</p>
<p>The Daily Python-URL is distinct from the Weekly Python-URL; read it
at <a class="reference" href="http://www.pythonware.com/daily/">http://www.pythonware.com/daily/</a>.  Postings vary from daily to weekly.</p>
<p><a class="reference" href="http://planet.python.org">http://planet.python.org</a> and <a class="reference" href="http://www.planetpython.org/">http://www.planetpython.org/</a> are Web sites
that aggregate Python blogs (mine included, hint hint).  Very much worth
skimming over a coffee break.</p>
<p>And, err, Google is a fantastic way to figure stuff out!</p>
</div>
<div class="section">
<h1><a class="toc-backref" href="#id71" id="wrapping-c-c-for-python" name="wrapping-c-c-for-python">Wrapping C/C++ for Python</a></h1>
<p>There are a number of options if you want to wrap existing C or C++
functionality in Python.</p>
<div class="section">
<h2><a class="toc-backref" href="#id72" id="manual-wrapping" name="manual-wrapping">Manual wrapping</a></h2>
<p>If you have a relatively small amount of C/C++ code to wrap, you can
do it by hand.  The <a class="reference" href="http://docs.python.org/ext/ext.html">Extending and Embedding</a> section of the docs is a pretty
good reference.</p>
<p>When I write wrappers for C and C++ code, I usually provide a procedural
interface to the code and then use Python to construct an object-oriented
interface.  I do things this way for two reasons: first, exposing C++
objects to Python is a pain; and second, I prefer writing higher-level
structures in Python to writing them in C++.</p>
<p>Let's take a look at a basic wrapper: we have a function 'hello' in a
file 'hello.c'.  'hello' is defined like so:</p>
<pre class="literal-block">
char * hello(char * what)
</pre>
<p>To wrap this manually, we need to do the following.</p>
<p>First, write a Python-callable function that takes in a string and returns
a string.</p>
<pre class="literal-block">
static PyObject * hello_wrapper(PyObject * self, PyObject * args)
{
  char * input;
  char * result;
  PyObject * ret;

  // parse arguments
  if (!PyArg_ParseTuple(args, &quot;s&quot;, &amp;input)) {
    return NULL;
  }

  // run the actual function
  result = hello(input);

  // build the resulting string into a Python object.
  ret = PyString_FromString(result);
  free(result);

  return ret;
}
</pre>
<p>Second, register this function within a module's symbol table (all Python
functions live in a module, even if they're actually C functions!)</p>
<pre class="literal-block">
static PyMethodDef HelloMethods[] = {
 { &quot;hello&quot;, hello_wrapper, METH_VARARGS, &quot;Say hello&quot; },
 { NULL, NULL, 0, NULL }
};
</pre>
<p>Third, write an init function for the module (all extension modules require
an init function).</p>
<pre class="literal-block">
DL_EXPORT(void) inithello(void)
{
  Py_InitModule(&quot;hello&quot;, HelloMethods);
}
</pre>
<p>Fourth, write a setup.py script:</p>
<pre class="literal-block">
from distutils.core import setup, Extension

# the c++ extension module
extension_mod = Extension(&quot;hello&quot;, [&quot;hellomodule.c&quot;, &quot;hello.c&quot;])

setup(name = &quot;hello&quot;, ext_modules=[extension_mod])
</pre>
<p>There are two aspects of this code that are worth discussing, even
at this simple level.</p>
<p>First, error handling: note the PyArg_ParseTuple call.  That call
is what tells Python that the 'hello' wrapper function takes precisely
one argument, a string (&quot;s&quot; means &quot;string&quot;; &quot;ss&quot; would mean &quot;two strings&quot;;
&quot;si&quot; would mean &quot;string and integer&quot;).  The convention in the C API to Python
is that a NULL return from a function that returns PyObject* indicates
an error has occurred; in this case, the error information is set
within PyArg_ParseTuple and we're just passing the error on up the stack
by returning NULL.</p>
<p>Second, references.  Python works on a system of reference counting:
each time a function &quot;takes ownership&quot; of an object (by, for example,
assigning it to a list, or a dictionary) it increments that object's
reference count by one using Py_INCREF.  When the object is removed
from use in that particular place (e.g. removed from the list or
dictionary), the reference count is decremented with Py_DECREF.  When
the reference count reaches 0, Python knows that this object is not
being used by anything and can be freed (it may not be freed immediately,
however).</p>
<p>Why does this matter?  Well, we're creating a PyObject in this code,
with PyString_FromString.  Do we need to INCREF it?  To find out,
go take a look at the documentation for PyString_FromString:</p>
<blockquote>
<a class="reference" href="http://docs.python.org/api/stringObjects.html#l2h-461">http://docs.python.org/api/stringObjects.html#l2h-461</a></blockquote>
<p>See where it says &quot;New reference&quot;?  That means it's handing back an
object with a reference count of 1, and that's what we want.  If it
had said &quot;Borrowed reference&quot;, then we would need to INCREF the object
before returning it, to indicate that we wanted the allocated memory to
survive past the end of the function.</p>
<p>Here's a way to think about references:</p>
<blockquote>
<ul class="simple">
<li>if you receive a Python object from the Python API, you can use it
within your own C code without INCREFing it.</li>
<li>if you want to guarantee that the Python object survives past the
end of your own C code, you must INCREF it.</li>
<li>if you received an object from Python code and it was a new reference,
but you don't want it to survive past the end of your own C code, you
should DECREF it.</li>
</ul>
</blockquote>
<p>If you wanted to return None, by the way, you can use Py_None.  Remember
to INCREF it!</p>
<p>Another note: during the class, I talked about using PyCObjects to
pass opaque C/C++ data types around.  This is useful if you are using
Python to organize your code, but you have complex structures that you
don't need to be Python-accessible.  You can wrap pointers in
PyCObjects (with an associated destructor, if so desired) at which
point they become opaque Python objects whose memory is managed by the
Python interpreter.  You can see an example in the example code, under
<tt class="docutils literal"><span class="pre">code/hello/hellmodule.c</span></tt>, functions <tt class="docutils literal"><span class="pre">cobj_in</span></tt>, <tt class="docutils literal"><span class="pre">cobj_out</span></tt>, and
<tt class="docutils literal"><span class="pre">free_my_struct</span></tt>, which pass an allocated C structure back to Python
using a PyCObject wrapper.</p>
<p>So that's a brief introduction to how you wrap things by hand.</p>
<p>As you might guess, however, there are a number of projects devoted
to automatically wrapping code.  Here's a brief introduction to some of
them.</p>
<!-- CTB: talk about testing c code with python? -->
<!-- Also pointers, deallocators.  (khmer?) -->
</div>
<div class="section">
<h2><a class="toc-backref" href="#id73" id="wrapping-python-code-with-swig" name="wrapping-python-code-with-swig">Wrapping Python code with SWIG</a></h2>
<p>SWIG stands for &quot;Simple Wrapper Interface Generator&quot;, and it is
capable of wrapping C in a large variety of languages.  To quote,
&quot;SWIG is used with different types of languages including common
scripting languages such as Perl, PHP, Python, Tcl, Ruby and PHP. The
list of supported languages also includes non-scripting languages such
as C#, Common Lisp (CLISP, Allegro CL, CFFI, UFFI), Java, Modula-3 and
OCAML. Also several interpreted and compiled Scheme implementations
(Guile, MzScheme, Chicken) are supported.&quot;</p>
<p>Whew.</p>
<p>But we only care about Python for now!</p>
<p>SWIG is essentially a macro language that groks C code and can spit
out wrapper code for your language of choice.</p>
<p>You'll need three things for a SWIG wrapping of our 'hello' program.
First, a Makefile:</p>
<pre class="literal-block">
all:
     swig -python -c++ -o _swigdemo_module.cc swigdemo.i
     python setup.py build_ext --inplace
</pre>
<p>This shows the steps we need to run: first, run SWIG to generate
the C code extension; then run <tt class="docutils literal"><span class="pre">setup.py</span> <span class="pre">build</span></tt> to actually build it.</p>
<p>Second, we need a SWIG wrapper file, 'swigdemo.i'.  In this case, it
can be pretty simple:</p>
<pre class="literal-block">
%module swigdemo

%{
#include &lt;stdlib.h&gt;
#include &quot;hello.h&quot;
%}

%include &quot;hello.h&quot;
</pre>
<p>A few things to note: the %module specifies the name of the module
to be generated from this wrapper file.  The code between the
%{ %} is placed, verbatim, in the C output file; in this case it
just includes two header files.  And, finally, the last line, %include,
just says &quot;build your interface against the declarations in this header
file&quot;.</p>
<p>OK, and third, we will need a setup.py.  This is virtually identical
to the setup.py we wrote for the manual wrapping:</p>
<pre class="literal-block">
from distutils.core import setup, Extension

extension_mod = Extension(&quot;_swigdemo&quot;, [&quot;_swigdemo_module.cc&quot;, &quot;hello.c&quot;])

setup(name = &quot;swigdemo&quot;, ext_modules=[extension_mod])
</pre>
<p>Now, when we run 'make', swig will generate the _swigdemo_module.cc
file, as well as a 'swigdemo.py' file; then, setup.py will compile the
two C files together into a single shared library, '_swigdemo', which
is imported by swigdemo.py; then the user can just 'import swigdemo'
and have direct access to everything in the wrapped module.</p>
<p>Note that swig can wrap most simple types &quot;out of the box&quot;.  It's only
when you get into your own types that you will have to worry about providing
what are called &quot;typemaps&quot;; I can show you some examples.</p>
<p>I've also heard (from someone in the class) that SWIG is essentially
not supported any more, so buyer beware.  (I will also say that SWIG
is pretty crufty.  When it works and does exactly what you want, your
life is good.  Fixing bugs in it is messy, though, as is adding new
features, because it's a template language, and hence many of the
constructs are ad hoc.)</p>
</div>
<div class="section">
<h2><a class="toc-backref" href="#id74" id="wrapping-c-code-with-pyrex" name="wrapping-c-code-with-pyrex">Wrapping C code with pyrex</a></h2>
<p>pyrex, as I discussed yesterday, is a weird hybrid of C and Python
that's meant for generating fast Python-esque code.  I'm not sure I'd
call this &quot;wrapping&quot;, but ... here goes.</p>
<p>First, write a .pyx file; in this case, I'm calling it 'hellomodule.pyx',
instead of 'hello.pyx', so that I don't get confused with 'hello.c'.</p>
<pre class="literal-block">
cdef extern from &quot;hello.h&quot;:
    char * hello(char *s)

def hello_fn(s):
    return hello(s)
</pre>
<p>What the 'cdef' says is, &quot;grab the symbol 'hello' from the file
'hello.h'&quot;.  Then you just go ahead and define your 'hello_fn' as
you would if it were Python.</p>
<p>and... that's it.  You've still got to write a setup.py, of course:</p>
<pre class="literal-block">
from distutils.core import setup
from distutils.extension import Extension
from Pyrex.Distutils import build_ext

setup(
  name = &quot;hello&quot;,
  ext_modules=[ Extension(&quot;hellomodule&quot;, [&quot;hellomodule.pyx&quot;, &quot;hello.c&quot;]) ],
  cmdclass = {'build_ext': build_ext}
)
</pre>
<p>but then you can just run 'setup.py build_ext --inplace' and you'll be able
to 'import hellomodule; hellomodule.hello_fn'.</p>
</div>
<div class="section">
<h2><a class="toc-backref" href="#id75" id="ctypes" name="ctypes">ctypes</a></h2>
<p>In Python 2.5, the ctypes module is included.  This module lets you
talk directly to shared libraries on both Windows and UNIX, which is
pretty darned handy.  But can it be used to call our C code directly?</p>
<p>The answer is yes, with a caveat or two.</p>
<p>First, you need to compile 'hello.c' into a shared library.</p>
<pre class="literal-block">
gcc -o hello.so -shared -fPIC hello.c
</pre>
<p>Then, you need to tell the system where to find the shared library.</p>
<pre class="literal-block">
export LD_LIBRARY_PATH=.
</pre>
<p>Now you can load the library with ctypes:</p>
<pre class="literal-block">
from ctypes import cdll

hello_lib = cdll.LoadLibrary(&quot;hello.so&quot;)
hello = hello_lib.hello
</pre>
<p>So far, so good -- now what happens if you run it?</p>
<pre class="literal-block">
&gt;&gt; print hello(&quot;world&quot;)
136040696
</pre>
<p>Whoops!  You still need to tell Python/ctypes what kind of return
value to expect!  In this case, we're expecting a char pointer:</p>
<pre class="literal-block">
from ctypes import c_char_p
hello.restype = c_char_p
</pre>
<p>And now it will work:</p>
<blockquote>
&gt;&gt; print hello(&quot;world&quot;)
hello, world</blockquote>
<p>Voila!</p>
<p>I should say that ctypes is not intended for this kind of wrapping,
because of the whole LD_LIBRARY_PATH setting requirement.  That is,
it's really intended for accessing <em>system</em> libraries.  But you can
still use it for other stuff like this.</p>
</div>
<div class="section">
<h2><a class="toc-backref" href="#id76" id="sip" name="sip">SIP</a></h2>
<p>SIP is the tool used to generate Python bindings for Qt (PyQt), a graphics
library.  However, it can be used to wrap any C or C++ API.</p>
<p>As with SWIG, you have to start with a definition file.  In this case,
it's pretty easy: just put this in 'hello.sip':</p>
<pre class="literal-block">
%CModule hellomodule 0

char * hello(char *);
</pre>
<p>Now you need to write a 'configure' script:</p>
<pre class="literal-block">
import os
import sipconfig

# The name of the SIP build file generated by SIP and used by the build
# system.
build_file = &quot;hello.sbf&quot;

# Get the SIP configuration information.
config = sipconfig.Configuration()

# Run SIP to generate the code.
os.system(&quot; &quot;.join([config.sip_bin, &quot;-c&quot;, &quot;.&quot;, &quot;-b&quot;, build_file, &quot;hello.sip&quot;]))

# Create the Makefile.
makefile = sipconfig.SIPModuleMakefile(config, build_file)

# Add the library we are wrapping.  The name doesn't include any platform
# specific prefixes or extensions (e.g. the &quot;lib&quot; prefix on UNIX, or the
# &quot;.dll&quot; extension on Windows).
makefile.extra_libs = [&quot;hello&quot;]
makefile.extra_lib_dirs = [&quot;.&quot;]

# Generate the Makefile itself.
makefile.generate()
</pre>
<p>Now, run 'configure.py', and then run 'make' on the generated Makefile,
and your extension will be compiled.</p>
<p>(At this point I should say that I haven't really used SIP before, and I
feel like it's much more powerful than this example would show you!)</p>
</div>
<div class="section">
<h2><a class="toc-backref" href="#id77" id="boost-python" name="boost-python">Boost.Python</a></h2>
<p>If you are an expert C++ programmer and want to wrap a lot of C++ code,
I would recommend taking a look at the Boost.Python library, which
lets you run C++ code from Python, and Python code from C++, seamlessly.
I haven't used it at all, and it's too complicated to cover in a short
period!</p>
<p><a class="reference" href="http://www.boost-consulting.com/writing/bpl.html">http://www.boost-consulting.com/writing/bpl.html</a></p>
</div>
<div class="section">
<h2><a class="toc-backref" href="#id78" id="recommendations" name="recommendations">Recommendations</a></h2>
<p>Based on my little survey above, I would suggest using SWIG to write
wrappers for relatively small libraries, while SIP probably provides a
more manageable infrastructure for wrapping large libraries (which I
know I did not demonstrate!)</p>
<p>Pyrex is astonishingly easy to use, and it may be a good option if you
have a small library to wrap.  My guess is that you would spend a lot
of time converting types back and forth from C/C++ to Python, but I could
be wrong.</p>
<p>ctypes is excellent if you have a bunch of functions to run and you don't
care about extracting complex data types from them: you just want to pass
around the encapsulated data types between the functions in order to
accomplish a goal.</p>
</div>
<div class="section">
<h2><a class="toc-backref" href="#id79" id="one-or-two-more-notes-on-wrapping" name="one-or-two-more-notes-on-wrapping">One or two more notes on wrapping</a></h2>
<p>As I said at the beginning, I tend to write procedural interfaces to
my C++ code and then use Python to wrap them in an object-oriented
interface.  This lets me adjust the OO structure of my code more
flexibly; on the flip side, I only use the code from Python, so I
really don't care what the C++ code looks like as long as it runs fast
;).  So, you might find it worthwhile to invest in figuring out how to
wrap things in a more object-oriented manner.</p>
<p>Secondly, one of the biggest benefits I find from wrapping my C code in
Python is that all of a sudden I can test it pretty easily.  Testing is
something you <em>do not</em> want to do in C, because you have to declare all
the variables and stuff that you use, and that just gets in the way of
writing simple tests.  I find that once I've wrapped something in Python,
it becomes much more testable.</p>
</div>
</div>
<div class="section">
<h1><a class="toc-backref" href="#id80" id="packages-for-multiprocessing" name="packages-for-multiprocessing">Packages for Multiprocessing</a></h1>
<div class="section">
<h2><a class="toc-backref" href="#id81" id="threading" name="threading">threading</a></h2>
<p>Python has basic support for threading built in: for example, here's a
program that runs two threads, each of which prints out messages after
sleeping a particular amount of time:</p>
<pre class="literal-block">
from threading import Thread, local
import time

class MessageThread(Thread):
    def __init__(self, message, sleep):
        self.message = message
        self.sleep = sleep
        Thread.__init__(self)                # remember to run Thread init!

    def run(self):                           # automatically run by 'start'
        i = 0
        while i &lt; 50:
            i += 1
            print i, self.message

            time.sleep(self.sleep)

t1 = MessageThread(&quot;thread - 1&quot;, 1)
t2 = MessageThread(&quot;thread - 2&quot;, 2)

t1.start()
t2.start()
</pre>
<p>However, due to the existence of the Global Interpreter Lock (GIL)
(<a class="reference" href="http://docs.python.org/api/threads.html">http://docs.python.org/api/threads.html</a>), CPU-intensive code will
not run faster on dual-core CPUs than it will on single-core CPUs.</p>
<p>Briefly, the idea is that the Python interpreter holds a global lock,
and no Python code can be executed without holding that lock.  (Code
execution will still be interleaved, but no two Python instructions
can execute at the same time.) Therefore, any Python code that you
write (or GIL-naive C/C++ extension code) will not take advantage of
multiple CPUs.</p>
<p>This is intentional:</p>
<blockquote>
<a class="reference" href="http://mail.python.org/pipermail/python-3000/2007-May/007414.html">http://mail.python.org/pipermail/python-3000/2007-May/007414.html</a></blockquote>
<p>There is a long history of wrangling about the GIL, and there are a couple
of good arguments for it.  Briefly,</p>
<blockquote>
<ul class="simple">
<li>it dramatically simplifies writing C extension code, because by
default, C extension code does not need to know anything about
threads.</li>
<li>putting in locks appropriately to handle places where contention
might occur is not only error-prone but makes the code quite slow;
locks really affect performance.</li>
<li>threaded code is difficult to debug, and most people don't need it,
despite having been brainwashed to think that they do ;).</li>
</ul>
</blockquote>
<p>But we don't care about that: <em>we</em> do want our code to run on multiple
CPUs.  So first, let's dip back into C code: what do we have to do to
make our C code release the GIL so that it can do a long computation?</p>
<p>Basically, just wrap I/O blocking code or CPU-intensive code in the
following macros:</p>
<pre class="literal-block">
Py_BEGIN_ALLOW_THREADS

...Do some time-consuming operation...

Py_END_ALLOW_THREADS
</pre>
<p>This is actually pretty easy to do to your C code, and it does result
in that code being run in parallel on multi-core CPUs.  (note:
example?)</p>
<p>The big problem with the GIL, however, is that it really means that you
simply can't write parallel code in Python without jumping through some
kind of hoop.  Below, we discuss a couple of these hoops ;).</p>
</div>
<div class="section">
<h2><a class="toc-backref" href="#id82" id="writing-and-indicating-threadsafe-c-extensions" name="writing-and-indicating-threadsafe-c-extensions">Writing (and indicating) threadsafe C extensions</a></h2>
<p>Suppose you had some CPU-expensive C code:</p>
<pre class="literal-block">
void waste_time() {
     int i, n;
     for (i = 0; i &lt; 1024*1024*1024; i++) {
         if ((i % 2) == 0) n++;
     }
}
</pre>
<p>and you wrapped this in a Python function:</p>
<pre class="literal-block">
PyObject * waste_time_fn(PyObject * self, PyObject * args) {
     waste_time();
}
</pre>
<p>Now, left like this, any call to <tt class="docutils literal"><span class="pre">waste_time_fn</span></tt> will cause all
Python threads and processes to block, waiting for <tt class="docutils literal"><span class="pre">waste_time</span></tt> to
finish.  That's silly, though -- <tt class="docutils literal"><span class="pre">waste_time</span></tt> is clearly threadsafe,
because it uses only local variables!</p>
<p>To tell Python that you are engaged in some expensive operations that
are threadsafe, just enclose the waste_time code like so:</p>
<pre class="literal-block">
PyObject * waste_time_fn(PyObject * self, PyObject * args) {
     Py_BEGIN_ALLOW_THREADS

     waste_time();

     Py_END_ALLOW_THREADS
}
</pre>
<p>This code will now be run in parallel when threading is used.  One
caveat: you can't do <em>any</em> call to the Python C API in the code
between the Py_BEGIN_ALLOW_THREADS and Py_END_ALLOW_THREADS, because
the Python C API is not threadsafe.</p>
</div>
<div class="section">
<h2><a class="toc-backref" href="#id83" id="parallelpython" name="parallelpython">parallelpython</a></h2>
<p>parallelpython is a system for controlling multiple Python processes on
multiple machines.  Here's an example program:</p>
<pre class="literal-block">
#!/usr/bin/python
def isprime(n):
    &quot;&quot;&quot;Returns True if n is prime and False otherwise&quot;&quot;&quot;
    import math

    if n &lt; 2:
        return False
    if n == 2:
        return True
    max = int(math.ceil(math.sqrt(n)))
    i = 2
    while i &lt;= max:
        if n % i == 0:
            return False
        i += 1
    return True

def sum_primes(n):
    &quot;&quot;&quot;Calculates sum of all primes below given integer n&quot;&quot;&quot;
    return sum([x for x in xrange(2, n) if isprime(x)])

####

import sys, time

import pp
# Creates jobserver with specified number of workers
job_server = pp.Server(ncpus=int(sys.argv[1]))

print &quot;Starting pp with&quot;, job_server.get_ncpus(), &quot;workers&quot;

start_time = time.time()

# Submit a job of calulating sum_primes(100) for execution.
#
#    * sum_primes - the function
#    * (input,) - tuple with arguments for sum_primes
#    * (isprime,) - tuple with functions on which sum_primes depends
#
# Execution starts as soon as one of the workers will become available

inputs = (100000, 100100, 100200, 100300, 100400, 100500, 100600, 100700)

jobs = []
for input in inputs:
    job = job_server.submit(sum_primes, (input,), (isprime,))
    jobs.append(job)

for job, input in zip(jobs, inputs):
    print &quot;Sum of primes below&quot;, input, &quot;is&quot;, job()

print &quot;Time elapsed: &quot;, time.time() - start_time, &quot;s&quot;
job_server.print_stats()
</pre>
<p>If you add &quot;ppservers=('host1')&quot; to to the line</p>
<pre class="literal-block">
pp.Server(...)
</pre>
<p>pp will check for parallelpython servers running on those other hosts and
send jobs to them as well.</p>
<p>The way parallelpython works is it literally sends the Python code across
the network &amp; evaluates it there!  It seems to work well.</p>
</div>
<div class="section">
<h2><a class="toc-backref" href="#id84" id="rpyc" name="rpyc">Rpyc</a></h2>
<p><a class="reference" href="http://rpyc.wikispaces.com/">Rpyc</a> is a remote procedure call system
built in (and tailored to) Python.  It is basically a way to transparently
control remote Python processes.  For example, here's some code that will
connect to an Rpyc server and ask the server to calculate the first
500 prime numbers:</p>
<pre class="literal-block">
from Rpyc import SocketConnection

# connect to the &quot;remote&quot; server
c = SocketConnection(&quot;localhost&quot;)

# make sure it has the right code in its path
c.modules.sys.path.append('/u/t/dev/misc/rpyc')

# tell it to execute 'primestuff.get_n_primes'
primes = c.modules.primestuff.get_n_primes(500)
print primes[-20:]
</pre>
<p>Note that this is a synchronous connection, so the client waits for the
result; you could also have it do the computation asynchronously, leaving
the client free to request results from other servers.</p>
<p>In terms of parallel computing, the server has to be controlled
directly, which makes it less than ideal.  I think parallelpython
is a better choice for straightforward number crunching.</p>
</div>
<div class="section">
<h2><a class="toc-backref" href="#id85" id="pympi" name="pympi">pyMPI</a></h2>
<p>pyMPI is a nice Python implementation to the MPI (message-passing
interface) library.  MPI enables different processors to communicate
with each other.  I can't demo pyMPI, because I couldn't get it to
work on my other machine, but here's some example code that computs pi
to a precision of 1e-6 on however many machines you have running MPI.</p>
<pre class="literal-block">
import random
import mpi

def computePi(nsamples):
    rank, size = mpi.rank, mpi.size
    oldpi, pi, mypi = 0.0,0.0,0.0

    done = False
    while(not done):
        inside = 0
        for i in xrange(nsamples):
            x = random.random()
            y = random.random()
            if ((x*x)+(y*y)&lt;1):
                inside+=1

        oldpi = pi
        mypi = (inside * 1.0)/nsamples
        pi =  (4.0 / mpi.size) * mpi.allreduce(mypi, mpi.SUM)

        delta = abs(pi - oldpi)
        if(mpi.rank==0):
            print &quot;pi:&quot;,pi,&quot; - delta:&quot;,delta
        if(delta &lt; 0.00001):
            done = True
    return pi

if __name__==&quot;__main__&quot;:
    pi = computePi(10000)
    if(mpi.rank==0):
        print &quot;Computed value of pi on&quot;,mpi.size,&quot;processors is&quot;,pi
</pre>
<p>One big problem with MPI is that documentation is essentially absent, but
I can still make a few points ;).</p>
<p>First, the &quot;magic&quot; happens in the 'allreduce' function up above, where
it sums the results from all of the machines and then divides by the
number of machines.</p>
<p>Second, pyMPI takes the unusual approach of actually building an
MPI-aware Python interpreter, so instead of running your scripts in
normal Python, you run them using 'pyMPI'.</p>
</div>
<div class="section">
<h2><a class="toc-backref" href="#id86" id="multitask" name="multitask">multitask</a></h2>
<p>multitask is not a multi-machine mechanism; it's a library that
implements cooperative multitasking around I/O operations.  Briefly,
whenever you're going to do an I/O operation (like wait for more
data from the network) you can tell multitask to yield to another
thread of control.  Here is a simple example where control is voluntarily
yielded after a 'print':</p>
<pre class="literal-block">
import multitask

 def printer(message):
     while True:
         print message
         yield

 multitask.add(printer('hello'))
 multitask.add(printer('goodbye'))
 multitask.run()
</pre>
<p>Here's another example from the home page:</p>
<pre class="literal-block">
import multitask

def listener(sock):
    while True:
        conn, address = (yield multitask.accept(sock))    # WAIT
        multitask.add(client_handler(conn))

def client_handler(sock):
    while True:
        request = (yield multitask.recv(sock, 1024))      # WAIT
        if not request:
            break
        response = handle_request(request)
        yield multitask.send(sock, response)              # WAIT

multitask.add(listener(sock))
multitask.run()
</pre>
</div>
</div>
<div class="section">
<h1><a class="toc-backref" href="#id87" id="useful-packages" name="useful-packages">Useful Packages</a></h1>
<div class="section">
<h2><a class="toc-backref" href="#id88" id="subprocess" name="subprocess">subprocess</a></h2>
<p>'subprocess' is a new addition (Python 2.4), and it provides a convenient
and powerful way to run system commands.  (...and you should use it instead
of os.system, commands.getstatusoutput, or any of the Popen modules).</p>
<p>Unfortunately subprocess is a bit hard to use at the moment; I'm hoping
to help fix that for Python 2.6, but in the meantime here are some basic
commands.</p>
<p>Let's just try running a system command and retrieving the output:</p>
<pre class="doctest-block">
&gt;&gt;&gt; import subprocess
&gt;&gt;&gt; p = subprocess.Popen(['/bin/echo', 'hello, world'], stdout=subprocess.PIPE)
&gt;&gt;&gt; (stdout, stderr) = p.communicate()
&gt;&gt;&gt; print stdout,
hello, world
</pre>
<p>What's going on is that we're starting a subprocess (running
'/bin/echo hello, world') and then asking for all of the output
aggregated together.</p>
<p>We could, for short strings, read directly from p.stdout (which is a file
handle):</p>
<pre class="doctest-block">
&gt;&gt;&gt; p = subprocess.Popen(['/bin/echo', 'hello, world'], stdout=subprocess.PIPE)
&gt;&gt;&gt; print p.stdout.read(),
hello, world
</pre>
<p>but you could run into trouble here if the command returns a lot of data;
you should use communicate to get the output instead.</p>
<p>Let's do something a bit more complicated, just to show you that it's
possible: we're going to write to 'cat' (which is basically an echo chamber):</p>
<pre class="doctest-block">
&gt;&gt;&gt; from subprocess import PIPE
&gt;&gt;&gt; p = subprocess.Popen([&quot;/bin/cat&quot;], stdin=PIPE, stdout=PIPE)
&gt;&gt;&gt; (stdout, stderr) = p.communicate('hello, world')
&gt;&gt;&gt; print stdout,
hello, world
</pre>
<p>There are a number of more complicated things you can do with subprocess --
like interact with the stdin and stdout of other processes -- but they
are fraught with peril.</p>
</div>
<div class="section">
<h2><a class="toc-backref" href="#id89" id="rpy" name="rpy">rpy</a></h2>
<p><a class="reference" href="http://rpy.sf.net/">rpy</a> is an extension for R that lets R and
Python talk naturally.  For those of you that have never used R, it's
a very nice package that's mainly used for statistics, and it has <em>tons</em>
of libraries.</p>
<p>To use rpy, just</p>
<pre class="literal-block">
from rpy import *
</pre>
<p>The most important symbol that will be imported is 'r', which lets you
run arbitrary R comments:</p>
<pre class="literal-block">
r(&quot;command&quot;)
</pre>
<p>For example, if you wanted to run a principle component analysis, you could
do it like so:</p>
<pre class="literal-block">
from rpy import *

def plot_pca(filename):
    r(&quot;&quot;&quot;data &lt;- read.delim('%s', header=FALSE, sep=&quot; &quot;, nrows=5000)&quot;&quot;&quot; \
      % (filename,))

    r(&quot;&quot;&quot;pca &lt;- prcomp(data, scale=FALSE, center=FALSE)&quot;&quot;&quot;)
    r(&quot;&quot;&quot;pairs(pca$x[,1:3], pch=20)&quot;&quot;&quot;)

plot_pca('vectors.txt')
</pre>
<p>Now, the problem with this code is that I'm really just using Python to
drive R, which seems inefficient.  You <em>can</em> go access the data directly
if you want; I'm just using R's loading features directly because they're
faster.  For example,</p>
<blockquote>
x = r.pca['x']</blockquote>
<p>is equivalent to 'x &lt;- pca$x'.</p>
</div>
<div class="section">
<h2><a class="toc-backref" href="#id90" id="matplotlib" name="matplotlib">matplotlib</a></h2>
<p><a class="reference" href="http://matplotlib.sf.net">matplotlib</a> is a plotting package that
aims to make &quot;simple things easy, and hard things possible&quot;.  It's got
a fair amount of matlab compatibility if you're into that.</p>
<p>Simple example:</p>
<pre class="literal-block">
x = [ i**2 for i in range(0, 500) ]
hist(x, 100)
</pre>
<!-- numpy/scipy -->
<!-- matplotlib -->
</div>
</div>
<div class="section">
<h1><a class="toc-backref" href="#id91" id="idiomatic-python-take-3-new-style-classes" name="idiomatic-python-take-3-new-style-classes">Idiomatic Python Take 3: new-style classes</a></h1>
<p>Someone (Lila) asked me a question about pickling and memory usage
that led me on a chase through google, and along the way I was
reminded that new-style classes do have one or two interesting
points.</p>
<p>You may remember from the first day that there was a brief discussion
of new-style classes.  Basically, they're classes that inherit from
'object' explicitly:</p>
<pre class="doctest-block">
&gt;&gt;&gt; class N(object):
...   pass
</pre>
<p>and they have a bunch of neat features (covered <a class="reference" href="http://www.python.org/download/releases/2.2.3/descrintro/">here</a> in
detail).  I'm going to talk about two of them: __slots__ and descriptors.</p>
<p>__slots__ are a memory optimization.  As you know, you can assign any
attribute you want to an object:</p>
<pre class="doctest-block">
&gt;&gt;&gt; n = N()
&gt;&gt;&gt; n.test = 'some string'
&gt;&gt;&gt; print n.test
some string
</pre>
<p>Now, the way this is implemented behind the scenes is that there's a
dictionary hiding in 'n' (called 'n.__dict__') that holds all of the
attributes.  However, dictionaries consume a fair bit of memory above
and beyond their contents, so it might be good to get rid of the dictionary
in some circumstances and specify precisely what attributes a class has.</p>
<p>You can do that by creating a __slots__ entry:</p>
<pre class="doctest-block">
&gt;&gt;&gt; class M(object):
...   __slots__ = ['x', 'y', 'z']
</pre>
<p>Now objects of type 'M' will contain only enough space to hold those three
attributes, and nothing else.</p>
<p>A side consequence of this is that you can no longer assign to arbitrary
attributes, however!</p>
<pre class="doctest-block">
&gt;&gt;&gt; m = M()
&gt;&gt;&gt; m.x = 5
&gt;&gt;&gt; m.a = 10
Traceback (most recent call last):
 ...
AttributeError: 'M' object has no attribute 'a'
</pre>
<p>This will look strangely like some kind of type declaration to people
familiar with B&amp;D languages, but I assure you that it is not!  You are
supposed to use __slots__ only for memory optimization...</p>
<p>Speaking of memory optimization (which is what got me onto this in the
first place) apparently using new-style classes and __slots__ both
dramatically decrease memory consumption:</p>
<blockquote>
<p><a class="reference" href="http://mail.python.org/pipermail/python-list/2004-November/291840.html">http://mail.python.org/pipermail/python-list/2004-November/291840.html</a></p>
<p><a class="reference" href="http://mail.python.org/pipermail/python-list/2004-November/291986.html">http://mail.python.org/pipermail/python-list/2004-November/291986.html</a></p>
</blockquote>
<div class="section">
<h2><a class="toc-backref" href="#id92" id="managed-attributes" name="managed-attributes">Managed attributes</a></h2>
<p>Another nifty pair of features in new-style classes are managed
attributes and descriptors.</p>
<p>You may know that in the olden days, you could intercept attribute access
by overwriting __getattr__:</p>
<pre class="doctest-block">
&gt;&gt;&gt; class A:
...    def __getattr__(self, name):
...        if name == 'special':
...           return 5
...        return self.__dict__[name]
&gt;&gt;&gt; a = A()
&gt;&gt;&gt; a.special
5
</pre>
<p>This turns out to be kind of inefficient, because <em>every</em> attribute access
now goes through __getattr__.  Plus, it's a bit ugly and it can lead to
buggy code.</p>
<p>Python 2.2 introduced &quot;managed attributes&quot;.  With managed attributes, you
can <em>define</em> functions that handle the get, set, and del operations for
an attribute:</p>
<pre class="doctest-block">
&gt;&gt;&gt; class B(object):
...   def _get_special(self):
...       return 5
...   special = property(_get_special)
&gt;&gt;&gt; b = B()
&gt;&gt;&gt; b.special
5
</pre>
<p>If you wanted to provide a '_set_special' function, you could do some
really bizarre things:</p>
<pre class="doctest-block">
&gt;&gt;&gt; class B(object):
...   def _get_special(self):
...      return 5
...   def _set_special(self, value):
...      print 'ignoring', value
...   special = property(_get_special, _set_special)
&gt;&gt;&gt; b = B()
</pre>
<p>Now, retrieving the value of the 'special' attribute will give you '5',
no matter what you set it to:</p>
<pre class="doctest-block">
&gt;&gt;&gt; b.special
5
&gt;&gt;&gt; b.special = 10
ignoring 10
&gt;&gt;&gt; b.special
5
</pre>
<p>Ignoring the array of perverse uses you could apply, this is actually
useful -- for one example, you can now do internal consistency checking
on attributes, intercepting inconsistent values before they actually get
set.</p>
</div>
<div class="section">
<h2><a class="toc-backref" href="#id93" id="descriptors" name="descriptors">Descriptors</a></h2>
<p>Descriptors are a related feature that let you implement attribute access
functions in a different way.  First, let's define a read-only descriptor:</p>
<pre class="doctest-block">
&gt;&gt;&gt; class D(object):
...   def __get__(self, obj, type=None):
...      print 'in get:', obj
...      return 6
</pre>
<p>Now attach it to a class:</p>
<pre class="doctest-block">
&gt;&gt;&gt; class A(object):
...   val = D()
</pre>
<pre class="doctest-block">
&gt;&gt;&gt; a = A()
&gt;&gt;&gt; a.val                               # doctest: +ELLIPSIS
in get: &lt;A object at ...&gt;
6
</pre>
<p>What happens is that 'a.val' is checked for the presence of a __get__ function,
and if such exists, it is called instead of returning 'val'.  You can also
do this with __set__ and __delete__:</p>
<pre class="doctest-block">
&gt;&gt;&gt; class D(object):
...   def __get__(self, obj, type=None):
...      print 'in get'
...      return 6
...
...   def __set__(self, obj, value):
...      print 'in set:', value
...
...   def __delete__(self, obj):
...      print 'in del'
</pre>
<pre class="doctest-block">
&gt;&gt;&gt; class A(object):
...   val = D()
&gt;&gt;&gt; a = A()
&gt;&gt;&gt; a.val = 15
in set: 15
&gt;&gt;&gt; del a.val
in del
&gt;&gt;&gt; print a.val
in get
6
</pre>
<p>This can actually give you control over things like the <em>types</em> of objects
that are assigned to particular classes: no mean thing.</p>
</div>
</div>
<div class="section">
<h1><a class="toc-backref" href="#id94" id="gui-gossip" name="gui-gossip">GUI Gossip</a></h1>
<p>Tkinter</p>
<blockquote>
<ul class="simple">
<li>fairly primitive;</li>
<li>but: comes with every Python install!</li>
<li>still a bit immature (feb 2007) for Mac OS X native (&quot;Aqua&quot;); X11 version
works fine on OS X.</li>
</ul>
</blockquote>
<p>PyQT (<a class="reference" href="http://www.riverbankcomputing.co.uk/pyqt/">http://www.riverbankcomputing.co.uk/pyqt/</a>)</p>
<blockquote>
<ul class="simple">
<li>mature;</li>
<li>cross platform;</li>
<li>freely available for Open Source Software use;</li>
<li>has a testing framework!</li>
</ul>
</blockquote>
<p>KWWidgets (<a class="reference" href="http://www.kwwidgets.org/">http://www.kwwidgets.org/</a>)</p>
<blockquote>
<ul class="simple">
<li>immature; based on Tk, so Mac OS X native is still a bit weak;</li>
<li>lightweight;</li>
<li>attractive;</li>
<li>has a testing framework!</li>
</ul>
</blockquote>
<p>pyFLTK (<a class="reference" href="http://sf.net/projects/pyfltk/">http://sf.net/projects/pyfltk/</a>)</p>
<blockquote>
<ul class="simple">
<li>cross platform;</li>
<li>FLTK is mature, although primitive;</li>
<li>not very pretty;</li>
<li>very lightweight;</li>
</ul>
</blockquote>
<p>wxWindows (<a class="reference" href="http://www.wxwindows.org/">http://www.wxwindows.org/</a>)</p>
<blockquote>
<ul class="simple">
<li>cross platform;</li>
<li>mature?; looks good.</li>
<li>no personal or &quot;friend&quot; experience;</li>
<li>try reading <a class="reference" href="http://www.ibm.com/developerworks/library/l-wxwin.html">http://www.ibm.com/developerworks/library/l-wxwin.html</a></li>
</ul>
</blockquote>
<p>pyGTK (<a class="reference" href="http://www.pygtk.org/">http://www.pygtk.org/</a>)</p>
<blockquote>
<ul class="simple">
<li>cross platform;</li>
<li>mature; looks good.</li>
<li>no personal or &quot;friend&quot; experience;</li>
<li>UI designer;</li>
</ul>
</blockquote>
<p>Mild recommendation: start with Qt, which is apparently very mature
and very powerful.</p>
</div>
<div class="section">
<h1><a class="toc-backref" href="#id95" id="python-3-0" name="python-3-0">Python 3.0</a></h1>
<p>What's coming in Python 3000 (a.k.a. Python 3.0)?</p>
<p>First of all, Python 3000 will be out sometime in 2008; large parts of
it have already been implemented.  It is simply an increment on the
current code base.</p>
<p>The biggest point is that Python 3000 will break backwards
compatibility, abruptly.  This is very unusual for Python, but is
necessary to get rid of some old cruft.  In general, Python has been
very good about updating slowly and incrementally without breaking
backwards compatibility very much; this approach is being abandoned
for the jump from 2.x to 3.x.</p>
<p>However, the actual impact of this is likely to be small.  There will
be a few expressions that no longer work -- for example, 'dict.has_key'
is being removed, because you can just do 'if key in dict' -- but a
lot of the changes are behind the scenes, e.g. functions that currently
return lists will return iterators (dict.iterkeys -&gt; dict.keys).</p>
<p>The biggest impact on this audience (scientists &amp; numerical people) is
probably that (in Python 3.0) 6 / 5 will no longer be 0, and &lt;&gt; is
being removed.</p>
<p>Where lots of existing code must be made Python 3k compatible, you will
be able to use an automated conversion tool.  This should &quot;just work&quot;
except for cases where there is ambiguity in intent.</p>
<p>The most depressing aspect of Py3k (for me) is that the stdlib is not
being reorganized, but this does mean that most existing modules will
still be in the same place!</p>
<p>See <a class="reference" href="http://www-03.ibm.com/developerworks/blogs/page/davidmertz?entry=second_day_python_3000">David Mertz's blog</a>
for his summary of the changes.</p>
</div>
</div>
</body>
</html>
